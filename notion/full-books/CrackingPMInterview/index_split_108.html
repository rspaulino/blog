<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Cracking the PM Interview: How to Land a Product Manager Job in Technology</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<p id="filepos765436" class="calibre_10"><span class="calibre2"><span class="bold">What You Need To Know</span></span></p><p class="calibre_11">If you’re a recent graduate from a strong computer science program, you probably know most of what you need to know. Focus more on practicing interview questions than relearning actual knowledge, unless you discover major gaps.</p><p class="calibre_1">Here’s the quick list of what you should know.</p><blockquote class="calibre_23">Note: we’re jumping right into big O notation to explain runtimes. If you don’t know big O or you are very vague on its meaning, you might want to jump ahead to read about it.</blockquote><p class="calibre_22"><span class="calibre4"><span class="bold">Data Structures</span></span></p><p class="calibre_14">As its name suggests, a data structure is a structure for holding data. Depending on what you’re optimizing for, there are many different approaches to holding or organizing your data.</p><p class="calibre_1">In roughly descending order of importance for an interview, the common data structures are:</p><p class="calibre_1"><span class="calibre4"><span class="italic">Arrays</span></span></p><p class="calibre_14">An array is the most straightforward way to hold a set of objects. It stores items in a simple list of objects. Looking up an object is fast if you know the index, but slow otherwise. For example, it’s fast to retrieve the 12th person in a list, but slow to find all people named “Alex” (since you have to look through all people).</p><p class="calibre_1">In most languages, an array cannot “grow” in length after being created. You must specify the length of the array upfront and it cannot be changed after that.</p><p class="calibre_12"><span class="italic"><span class="bold">Good Practice Problems:</span></span></p><p class="calibre_32"><span class="calibre4"><span class="bold">16.1</span></span><span class="calibre4"> Given a sorted array of positive integers with an empty spot (zero) at the end, insert an element in sorted order. </span><a id="filepos767574"></a></p><blockquote class="calibre_52"><a href="index_split_113.html#filepos830673"><span class="calibre_53">jump to solution</span></a></blockquote><p class="calibre_54"><span class="calibre4"><span class="bold">16.2</span></span><span class="calibre4"> Reverse the order of elements in an array (without creating a new array). </span><a id="filepos767878"></a></p><blockquote class="calibre_52"><a href="index_split_113.html#filepos840470"><span class="calibre_53">jump to solution</span></a></blockquote><p class="calibre_51"><span class="calibre4"><span class="italic">Hashtables</span></span></p><p class="calibre_14">A hashtable (sometimes called a “dictionary” or a “hashmap”) allows you to map a “key” to a “value.” This key is often a number or string, and the value can be any type of object.</p><p class="calibre_1">This is a very useful data structure because it allows for very fast lookup. For the purposes of an interview, we generally assume that a hashtable is O(1) (constant time, regardless of the amount of data) to insert and look up elements, even though this isn’t 100 percent true. A poor implementation of a hashtable could have an O(N) look-up time.</p><p class="calibre_1">You might use it to map from a person’s ID number to some object with other information about them.</p><p class="calibre_12"><span class="italic"><span class="bold">Good Practice Problems</span></span></p><p class="calibre_32"><span class="calibre4"><span class="bold">16.3</span></span><span class="calibre4"> Given two lists (A and B) of unique strings, write a program to determine if A is a subset of B. That is, check if all the elements from A are contained in B. </span><a id="filepos769225"></a></p><blockquote class="calibre_52"><a href="index_split_113.html#filepos843695"><span class="calibre_53">jump to solution</span></a></blockquote><p class="calibre_54"><span class="calibre4"><span class="bold">16.4</span></span><span class="calibre4"> You are given a two-dimensional array of sales data where the first column is a product ID and the second column is the quantity. Write a function to take this list of data and return a new two-dimensional array with the total sales for each product ID. </span><a id="filepos769709"></a></p><blockquote class="calibre_5">Example: </blockquote><blockquote class="calibre_55"><tt class="calibre10">211,4 </tt></blockquote><blockquote class="calibre_55"><tt class="calibre10">262,3 </tt></blockquote><blockquote class="calibre_55"><tt class="calibre10">211,5 </tt></blockquote><blockquote class="calibre_55"><tt class="calibre10">216,6</tt></blockquote><blockquote class="calibre_55">Output: </blockquote><blockquote class="calibre_55"><tt class="calibre10">211,9 </tt></blockquote><blockquote class="calibre_55"><tt class="calibre10">262,3 </tt></blockquote><blockquote class="calibre_55"><tt class="calibre10">216,6</tt></blockquote><blockquote class="calibre_56"><a href="index_split_113.html#filepos850066"><span class="calibre_53">jump to solution</span></a></blockquote><p class="calibre_51"><span class="calibre4"><span class="italic">Trees and Graphs</span></span></p><p class="calibre_14">A <span class="bold">graph</span> is a set of nodes which are connected through edges. Not all the nodes need to be connected—you could have two entirely separate subgraphs—and the edges can be either “directed” or “undirected.” A directed edge can be thought of as a one-way street, with an undirected edge being like a two-way street. If the graph is directed, an edge from <span class="italic">v</span> to <span class="italic">w</span> is not an edge from <span class="italic">w</span> to <span class="italic">v</span>. Therefore, you might be able to “drive” from node <span class="italic">n</span> to node <span class="italic">m</span>, but not the other way around.</p><p class="calibre_1">A <span class="bold">tree</span> is a type of graph in which any two nodes are connected through one, and only one, path. A tree will not have any cycles since there can only be one path between any two nodes.</p><p class="calibre_1">A tree can come in many forms, but by far the most common is the <span class="bold">binary tree</span>. A binary tree is a tree where each node has only two child nodes. We call these nodes the left node and the right node. As with all trees, there cannot be any “cycles” on the tree (no paths from a node back to itself). Because of these restrictions, a binary tree can be represented in a strictly hierarchical fashion like this:</p><p class="calibre_2"><img src="images/00011.jpg" class="calibre_57"/></p><p class="calibre_31">Commonly, we work with <span class="bold">binary search trees</span>. A binary search tree is a tree in which all nodes in the left subtree are less than the node’s value, which is in turn less than the values of the all nodes in the right subtree. The above tree is a binary search tree.</p><p class="calibre_1">If a binary search tree is balanced (and usually we deal with balanced binary search trees), inserting an element, as well as finding an element, is O(log n) where n is the number of nodes.</p><p class="calibre_12"><span class="italic"><span class="bold">Good Practice Problems</span></span></p><p class="calibre_32"><span class="calibre4"><span class="bold">16.5</span></span><span class="calibre4"> Insert an element into a binary search tree (in order). You may assume that the binary search tree contains integers. </span><a id="filepos772918"></a></p><blockquote class="calibre_52"><a href="index_split_113.html#filepos855083"><span class="calibre_53">jump to solution</span></a></blockquote><p class="calibre_54"><span class="calibre4"><span class="bold">16.6</span></span><span class="calibre4"> Given a binary search tree which contains integers as values, calculate the sum of all the numbers. </span><a id="filepos773248"></a></p><blockquote class="calibre_52"><a href="index_split_113.html#filepos859366"><span class="calibre_53">jump to solution</span></a></blockquote><p class="calibre_51"><span class="calibre4"><span class="italic">Linked Lists</span></span></p><p class="calibre_14">Like a binary tree, a linked list is a data structure composed of nodes, where each node has a pointer to other nodes. In a singly-linked list, the node only has a pointer to its next node. In a doubly-linked list, the node has pointers to its previous node and its next node. It is generally considered highly problematic, and possibly a violation of the linked list structure, if the list has a cycle.</p><p class="calibre_1">Inserting a node into the front of a linked list can be done in O(1) time. However, if the list is sorted and you wish to insert the node in order, it will take O(N) time, where N is the number of nodes. This is because you must first find the right spot, and this requires searching through the whole list.</p><p class="calibre_1">Finding a node in a linked list is O(N), whether or not the list is sorted.</p><p class="calibre_12"><span class="italic"><span class="bold">Good Practice Problems</span></span></p><p class="calibre_32"><span class="calibre4"><span class="bold">16.7</span></span><span class="calibre4"> Insert a node into a sorted linked list (in order). (Don’t forget about what happens when the new element is at the start or end!) </span><a id="filepos774710"></a></p><blockquote class="calibre_52"><a href="index_split_113.html#filepos864850"><span class="calibre_53">jump to solution</span></a></blockquote><p class="calibre_54"><span class="calibre4"><span class="bold">16.8</span></span><span class="calibre4"> “Sort” a linked list that contains just 0s and 1s. That is, modify the list such that all 0s come before all 1s. </span><a id="filepos775057"></a></p><blockquote class="calibre_52"><a href="index_split_113.html#filepos869379"><span class="calibre_53">jump to solution</span></a></blockquote><p class="calibre_51"><span class="calibre4"><span class="italic">Stack</span></span></p><p class="calibre_14">A stack is a data structure which defines a precise order for how elements must be inserted and removed. When an element is added, or “pushed,” it is inserted on the top of the stack. When an element is removed, it is “popped” from the top of the stack.</p><p class="calibre_1">A stack is said to be a LIFO (last-in-first-out) data structure, since the last (most recent) element added is the first one to be removed.</p><p class="calibre_1">In this way, it acts like a stack of plates in real life. When you add a plate onto a stack of plates, you add it on the top. When you remove a plate, you always remove from the top.</p><p class="calibre_1">Inserting and removing from a stack is O(1). Finding an element with a particular value is not usually done, as it would require removing all the elements, one by one. A stack is not a good data structure choice if this is something you think you will need to do.</p><p class="calibre_12"><span class="italic"><span class="bold">Good Practice Problems</span></span></p><p class="calibre_32"><span class="calibre4"><span class="bold">16.9</span></span><span class="calibre4"> Write a function which takes a stack as input and returns a new stack which has the elements reversed. </span><a id="filepos776590"></a></p><blockquote class="calibre_52"><a href="index_split_113.html#filepos890320"><span class="calibre_53">jump to solution</span></a></blockquote><p class="calibre_54"><span class="calibre4"><span class="bold">16.10</span></span><span class="calibre4"> Write a function which removes all the even numbers from a stack. You should return the original stack, not a new one. </span><a id="filepos776940"></a></p><blockquote class="calibre_52"><a href="index_split_113.html#filepos894556"><span class="calibre_53">jump to solution</span></a></blockquote><p class="calibre_51"><span class="calibre4"><span class="italic">Queue</span></span></p><p class="calibre_14">A queue is essentially the opposite of a stack. Rather than removing the newest item with a LIFO (last-in-first-out) principle, it removes the oldest item. It is said to be “FIFO” (first-in-first-out), since the first item you add will be the first one you remove.</p><p class="calibre_1">It acts like a queue (or line) in real life. When people are in a queue for movie tickets, the first person to get in line is the first person who will be served. This is of course how the data structure gets its name.</p><p class="calibre_1">Inserting (or “enqueuing”) and removing (or “dequeuing”) from a queue is O(1). As in a stack, finding an element would not ordinarily be implemented.</p><p class="calibre_12"><span class="italic"><span class="bold">Good Practice Problems</span></span></p><p class="calibre_32"><span class="calibre4"><span class="bold">16.11</span></span><span class="calibre4"> Write a function to check if two queues are identical (same values in the same order). It’s okay to modify/destroy the two queues. </span><a id="filepos778254"></a></p><blockquote class="calibre_52"><a href="index_split_113.html#filepos897423"><span class="calibre_53">jump to solution</span></a></blockquote><p class="calibre_54"><span class="calibre4"><span class="bold">16.12</span></span><a id="filepos778462"></a><span class="calibre4"> Write a function to remove the 13th element from a queue (but keep all the other elements in place and in the same order). </span></p><blockquote class="calibre_52"><a href="index_split_113.html#filepos900808"><span class="calibre_53">jump to solution</span></a></blockquote><p class="calibre_51"><span class="calibre4"><span class="bold">Algorithms</span></span></p><p class="calibre_14">If you have a computer science degree, you know we could easily fill hundreds of pages with advanced algorithms. We won’t though, because these topics are rarely asked in interviews. Even developers are unlikely to be asked questions about, say, Dijkstra’s Algorithm, since interviewers care much more about your ability to create a <span class="italic">new</span> algorithm than memorizing an existing one.</p><p class="calibre_1">Still, there are a few fundamental algorithms that are considered “fair game” for developers, and even for PMs. These come up frequently enough that it’s worth your time to remember them.</p><p class="calibre_1"><span class="calibre4"><span class="italic">Sorting</span></span></p><p class="calibre_14">The two most common <span class="italic">good</span> ways to sort an array are quick sort and merge sort. The others—bubble sort, insertion sort, radix sort, etc.—are less efficient in general or only work with specific assumptions.</p><div class="calibre_15"> </div><ul class="calibre_16"><li value="1" class="calibre_29"><span class="bold">Merge Sort</span> operates by sorting the left and right half of the array, and then merging the arrays. How does it sort the left and right halves? Through the merge sort algorithm (recursively). It takes the left half, divides that in half, sorts each part, and then merges those together. It then does the same on the right half. Merge Sort is O(n log(n)) in the average case and in the worst case.</li><li value="2" class="calibre_29"><span class="bold">Quick Sort</span> sorts data by choosing a random “pivot” element and rearranging the elements in the array based on whether they’re less than or greater than the pivot. Next, it tackles the elements on the left side of the pivot (all of which are less than or equal to the pivot) and the right half of the pivot (all of which are greater than the pivot). It applies the same strategy to each side: pick a pivot, rearrange, and then pick a new pivot on each side. Quick Sort is O(n log(n)) in the average case, but O(n<sup class="calibre11"><small class="calibre12">2</small></sup>) in the worst case. The worst case will happen if a bad “pivot” (a very low or very high element) is continuously picked.</li></ul><p class="calibre_1">Note that both algorithms have an approach of “divide in two parts and then re-apply algorithm.”</p><p class="calibre_1">The other sorting algorithms are the naive implementations that you might do when, say, you’re trying to sort a stack of papers.</p><div class="calibre_15"> </div><ul class="calibre_16"><li value="1" class="calibre_29"><span class="bold">Insertion Sort</span> maintains a sorted sublist of elements (initially 0) at the beginning of the array. It then looks at the beginning of the unsorted sublist. If this element is bigger than the last element in the sorted sublist, it leaves it in place and just grows the sorted portion (since the element is already in the correct order). If it’s smaller, then it moves it into place in the sorted sublist. The unsorted portion shrinks by one each time. The algorithm then repeats this step for each element in the unsorted portion, until the array is fully sorted. Insertion Sort takes O(N) time in the best case (if the array is already sorted), but O(N<sup class="calibre11"><small class="calibre12">2</small></sup>) in the expected and worst case.</li><li value="2" class="calibre_29"><span class="bold">Bubble Sort</span> is a pretty straightforward algorithm. It iterates through the list repeatedly, swapping each pair of elements that are out of order. Once a full iteration happens without any swaps, the array is sorted. This takes O(N) in the best case (if the array is totally sorted) and O(N<sup class="calibre11"><small class="calibre12">2</small></sup>) in the expected and worst case.</li></ul><p class="calibre_1">It’s unlikely that you’ll be asked to implement one of these algorithms by name, but it’s still useful to understand how one might sort data. PMs are sometimes asked to sort a list of data. Those with a recent CS degree would likely be expected to implement one of the more optimal algorithms, while those without a CS degree may get away with the more naive approaches.</p><p class="calibre_12"><span class="italic"><span class="bold">Good Practice Problems</span></span></p><p class="calibre_32"><span class="calibre4"><span class="bold">16.13</span></span><span class="calibre4"> Given two sorted arrays, write a function to merge them in sorted order into a new array. </span><a id="filepos783389"></a></p><blockquote class="calibre_52"><a href="index_split_113.html#filepos904372"><span class="calibre_53">jump to solution</span></a></blockquote><p class="calibre_54"><span class="calibre4"><span class="bold">16.14</span></span><a id="filepos783597"></a><span class="calibre4"> Implement insertion sort. </span></p><blockquote class="calibre_52"><a href="index_split_113.html#filepos912293"><span class="calibre_53">jump to solution</span></a></blockquote><p class="calibre_51"><span class="calibre4"><span class="italic">Binary Search</span></span></p><p class="calibre_14">Binary search is an algorithm for locating a value in a sorted list (typically an array). In binary search, we compare the value to the midpoint of our list. Since our list is sorted, we can then determine whether the value should be located on the left side or the right side of this comparison element. We then search the left or right side, repeating this operation: compare to midpoint of the sublist, and then search the left or right half of that sublist.</p><p class="calibre_1">Because we’re repeatedly dividing the data set in half, the algorithm takes O(log n) time in the average and worst case.</p><p class="calibre_1">We often perform binary search in real life without realizing it. Imagine you had a stack of student exams sorted by first name. If you had a name like “Peter,” would you search starting from the top of the stack? Probably not. You would hop about halfway through, and then compare. If you see “Mary,” you know to keep going. You could then just search that second half of exams by continuously dividing the stack in half.</p><p class="calibre_1">Binary search is a popular algorithm and therefore an important concept to understand. Many algorithms are based on binary search.</p><p class="calibre_12"><span class="italic"><span class="bold">Good Practice Problems</span></span></p><p class="calibre_32"><span class="calibre4"><span class="bold">16.15</span></span><span class="calibre4"> Implement binary search. That is, given a sorted array of integers and a value, find the location of that value. </span><a id="filepos785496"></a></p><blockquote class="calibre_52"><a href="index_split_113.html#filepos916216"><span class="calibre_53">jump to solution</span></a></blockquote><p class="calibre_54"><span class="calibre4"><span class="bold">16.16</span></span><span class="calibre4"> You are given an integer array which </span><a id="filepos785764"></a><span class="calibre4"><span class="italic">was</span></span><span class="calibre4"> sorted, but then rotated. It contains all distinct elements. Find the minimum value. For example, the array might be 6, 8, 9, 11, 15, 20, 3, 4, 5. The minimum value would obviously be 3. </span></p><blockquote class="calibre_52"><a href="index_split_113.html#filepos921659"><span class="calibre_53">jump to solution</span></a></blockquote><p class="calibre_51"><span class="calibre4"><span class="italic">Graph Search</span></span></p><p class="calibre_14">There are two common algorithms for searching a graph: depth-first search and breadth-first search.</p><p class="calibre_1">In depth-first search, we will completely search a node’s first child before going on to the second child, third child, and so on. For example, imagine a node with two children, A and B. If we are searching for a value v, we completely search A (and the nodes connected to A) before we check out B. It’s called “depth-first search” for this reason; we go deep before we go wide.</p><p class="calibre_1">In breadth-first search, we go wide before deep. If we start from an initial node R, we first check R and all the nodes immediately connected to R (let’s call these “children”). Then, we expand our search outwards, searching all the nodes connected to R’s children. We repeat this process until we find the value or until we’ve completed searching this entire [sub-]graph.</p><p class="calibre_1">In both algorithms, we need to be careful that we don’t wind up going in circles forever. Therefore, if there are cycles in the graph—that is, if there is more than one path to get from one node to another—then we need to mark the nodes as “already visited” to ensure that we don’t repeatedly search the same node. This will not be an issue for trees, as there are no cycles in a tree.</p><p class="calibre_1">Note that a graph <span class="italic">can</span> have two completely separate parts that are not connected. If this is the case, we need to perform our search algorithm on each component to ensure that we find the item we’re looking for.</p><p class="calibre_12"><span class="italic"><span class="bold">Good Practice Problems</span></span></p><p class="calibre_32"><span class="calibre4"><span class="bold">16.17</span></span><a id="filepos788107"></a><span class="calibre4"> Using depth-first search, check if a tree contains a value. </span></p><blockquote class="calibre_52"><a href="index_split_113.html#filepos927668"><span class="calibre_53">jump to solution</span></a></blockquote><p class="calibre_54"><span class="calibre4"><span class="bold">16.18</span></span><span class="calibre4"> Write the pseudocode for breadth-first search on a binary tree. Try to be as detailed as possible. </span><a id="filepos788520"></a></p><blockquote class="calibre_52"><a href="index_split_113.html#filepos930273"><span class="calibre_53">jump to solution</span></a></blockquote><p class="calibre_51"><span class="calibre4"><span class="bold">Concepts</span></span></p><p class="calibre_14"><span class="calibre4"><span class="italic">Big O Notation</span></span></p><p class="calibre_14">Big O notation is a way to express the efficiency of an algorithm. If you’re going to be working with code, it is important that you understand big O. It is, quite literally, the language we use to express efficiency.</p><p class="calibre_1">Big O will allow you understand the tradeoff of different features. For example, if you were working on a social networking website and you wanted to show how many friends two people have in common, you might suggest looking through each of my friends to see if the friend is in your list of friends. This probably takes O(N<sup class="calibre11"><small class="calibre12">2</small></sup>) time, where N is the average number of friends a user has. That is, if you were to time how long this approach took as friends lists grew bigger and bigger, you would see that the graph of runtimes looks something like the f(x) = x<sup class="calibre11"><small class="calibre12">2</small></sup> graph. This is going to be very costly. You’ll need to come up with a better implementation.</p><p class="calibre_2"><img src="images/00014.jpg" class="calibre_58"/><span class="calibre6">f(x) = x<sup class="calibre13"><small class="calibre12"><span class="calibre14">2</span></small></sup></span></p><p class="calibre_1">Big O allows you to state this sort of information clearly and succinctly. It expresses how the execution time of a program scales with the input data. That is, as the input gets bigger, how much longer will the program take? Just a little bit longer? A lot longer? Will the time increase, say, exponentially with the size of input (yikes!)?</p><p class="calibre_1">Suppose you have a function <span class="italic">foo</span> which does some processing on an array of size <span class="italic">N</span>. If foo takes O(N) time, then, as the array grows (that is, as N increases), the number of seconds foo takes will also increase in some sort of linear fashion.</p><p class="calibre_12"><span class="italic"><span class="bold">Carrier Pigeons vs. The Internet</span></span></p><p class="calibre_31">This is a true story.</p><p class="calibre_1">In 2009, a South African company named The Unlimited grew frustrated by their ISP’s slow internet and made news by comically showing just how bad it was. They “raced” a carrier pigeon against their ISP. The pigeon had a USB stick affixed to its leg and was taught to fly to an office 50 miles away. Meanwhile, the company transferred this same data over the internet to this same office. The pigeon won—by a long shot.</p><p class="calibre_1">What a joke this ISP was, right? A bird could transfer data faster than them. A bird!</p><p class="calibre_1">Their internet may or may not have been slow, but this experiment doesn’t say much. No matter how fast or slow your internet is, you can select an amount of data that will allow the internet or a pigeon to win.</p><p class="calibre_1">Here’s why:</p><p class="calibre_1">How long does it take a pigeon to fly 50 miles with a 10 GB USB stick attached to its leg? Let’s say it takes about 3 hours. Great.</p><p class="calibre_1">Now, how long does it take to transfer 10 GB on the internet? Let’s say you have pretty fast internet, and 10 GB only takes 30 minutes. Okay, then transfer 100 GB and you know it will take more than 3 hours.</p><p class="calibre_1">How long does it take that same pigeon to “transfer” 100 GB? Still 3 hours. The pigeon’s transfer speed doesn’t depend on the amount of data. USB sticks are pretty light but can fit a ton of data. (This is a bit of an oversimplification, of course. With enough data, you would need many USB sticks and eventually many pigeons.)</p><p class="calibre_1"><span class="italic">So, just like that, the pigeon beat the internet!</span></p><p class="calibre_1">The pigeon’s transfer time is constant. The internet’s transfer time is proportional to the amount of data: twice the data will take about twice as much time.</p><p class="calibre_1">In big O time, we’d say that the pigeon takes O(1) time. This means that the time it takes to transfer N gigabytes varies proportionally with 1. That is, it doesn’t vary at all.</p><p class="calibre_1">The internet’s transfer speed is O(N). This means that the amount of time it takes varies proportionally with N.</p><p class="calibre_1">Big O offers an equation to describe how the time of a procedure changes relative to its input. It describes the trend. It does not define exactly how long it takes, as procedures with larger big O time could be faster on specific inputs.</p><p class="calibre_12"><span class="italic"><span class="bold">Real-Life Big O</span></span></p><p class="calibre_31">Many “operations” in real life are O(N). Driving, for example, can be thought of as O(N). As the distance <span class="italic">N</span> increases, driving time also increases in a linear fashion.</p><p class="calibre_1">What might not be O(N)?</p><p class="calibre_1">Imagine we invited a bunch of people (including you) to a dinner party. If I invited twice as many people to the party, you will have to shake twice as many hands. The time it will take <span class="italic">you</span> to shake everyone’s hand can be expressed as O(N). If I double the amount of guests, it will take you twice as long. This is a linear, or O(N), increase.</p><p class="calibre_1">Now, let’s suppose everyone wants to shake hands, but for some strange reason only one pair of people can shake hands at a time. As N increases, how much longer will this meet and greet take? Well, your work will take O(N) time—but so will everyone else’s. The time it takes increases <span class="italic">proportionally</span> with O(N<sup class="calibre11"><small class="calibre12">2</small></sup>), since there are roughly N<sup class="calibre11"><small class="calibre12">2</small></sup> pairs.</p><p class="calibre_12"><span class="italic"><span class="bold">Dropping Constants</span></span></p><p class="calibre_31">If you are paying close attention, you might say, “But wait! There aren’t N<sup class="calibre11"><small class="calibre12">2</small></sup> pairs. People aren’t shaking hands with themselves, and you’re double counting every pair. There are really N(N-1)/2 pairs. So we should say O(N(N-1)/2).”</p><p class="calibre_1">You’re absolutely right. There <span class="italic">are</span> N(N-1)/2 pairs (which is .5*N<sup class="calibre11"><small class="calibre12">2</small></sup> - .5N), but we still say that this is O(N<sup class="calibre11"><small class="calibre12">2</small></sup>).</p><p class="calibre_1">Big O is very hand-wavey, wishy-washy. We’re trying to express how the time changes in rough terms, not offer a precise calculation for the number of seconds something takes.</p><p class="calibre_1">As a result, we drop constant factors, so O(2N) is the same as O(N). We also drop the addition or subtraction of constants, so O(N - 5) becomes O(N). Put together, these two factors mean that O(N<sup class="calibre11"><small class="calibre12">2</small></sup> + N) should be written as O(N<sup class="calibre11"><small class="calibre12">2</small></sup>). Think about it: if O(N<sup class="calibre11"><small class="calibre12">2</small></sup>) and O(N<sup class="calibre11"><small class="calibre12">2</small></sup> + N<sup class="calibre11"><small class="calibre12">2</small></sup>) are the same, then O(N<sup class="calibre11"><small class="calibre12">2</small></sup> + N), which is between those two, should be treated as the same.</p><p class="calibre_1">This is a very important thing to understand. You should never express an algorithm as “O(2N).” This is not a “more precise” or “better” answer than O(N); it’s only a confusing one. A so-called “O(2N)” algorithm is O(N) and should be expressed as such.</p><p class="calibre_1">Which of the below expressions are equivalent to O(N<sup class="calibre11"><small class="calibre12">3</small></sup>)?</p><blockquote class="calibre_23"><tt class="calibre10">O(3N<sup class="calibre11"><small class="calibre12"><tt class="calibre10">3</tt></small></sup>)</tt></blockquote><blockquote class="calibre_5"><tt class="calibre10">O(N(N<sup class="calibre11"><small class="calibre12"><tt class="calibre10">2</tt></small></sup></tt><span class="calibre6"><tt class="calibre10">
</tt></span><tt class="calibre10">+ 3)</tt><span class="calibre6"><tt class="calibre10">)</tt></span></blockquote><blockquote class="calibre_5"><tt class="calibre10">O(N<sup class="calibre11"><small class="calibre12"><tt class="calibre10">3</tt></small></sup></tt><span class="calibre6"><tt class="calibre10">
</tt></span><tt class="calibre10">- 2)</tt></blockquote><blockquote class="calibre_5"><tt class="calibre10">O(N<sup class="calibre11"><small class="calibre12"><tt class="calibre10">3</tt></small></sup></tt><span class="calibre6"><tt class="calibre10">
</tt></span><tt class="calibre10">+</tt><span class="calibre6"><tt class="calibre10">
</tt></span><tt class="calibre10">N</tt><span class="calibre6"><tt class="calibre10">
</tt></span><tt class="calibre10">lg</tt><span class="calibre6"><tt class="calibre10">
</tt></span><tt class="calibre10">N)</tt></blockquote><blockquote class="calibre_5"><tt class="calibre10">O(N<sup class="calibre11"><small class="calibre12"><tt class="calibre10">3</tt></small></sup></tt><span class="calibre6"><tt class="calibre10">
</tt></span><tt class="calibre10">-</tt><span class="calibre6"><tt class="calibre10">
</tt></span><tt class="calibre10">N<sup class="calibre11"><small class="calibre12"><tt class="calibre10">2</tt></small></sup></tt><span class="calibre6"><tt class="calibre10">
</tt></span><tt class="calibre10">+</tt><span class="calibre6"><tt class="calibre10">
</tt></span><tt class="calibre10">N)</tt></blockquote><blockquote class="calibre_5"><tt class="calibre10">O((N<sup class="calibre11"><small class="calibre12"><tt class="calibre10">2</tt></small></sup></tt><span class="calibre6"><tt class="calibre10">
</tt></span><tt class="calibre10">+ 3)</tt><span class="calibre6"><tt class="calibre10">(</tt></span><tt class="calibre10">N</tt><span class="calibre6"><tt class="calibre10">+1))</tt></span></blockquote><p class="calibre_31">All of them!</p><p class="calibre_1">Drop your constants and just keep the most important term.</p><p class="calibre_12"><span class="italic"><span class="bold">Multiple Variables</span></span></p><p class="calibre_31">Back to the handshaking example. Suppose we invited men and women to our dinner party. All the men already know each other and all the women already know each other. Therefore, people will only shake hands with the opposite gender.</p><p class="calibre_1">Assuming that we’re still in bizarro land where only one pair can shake hands at a time, how would you express how long this takes?</p><p class="calibre_1">Don’t say O(N<sup class="calibre11"><small class="calibre12">2</small></sup>). Suppose we have 100 men and 1 woman. Adding one man will add one handshake, but adding one woman will add 100 handshakes. The time it takes does not actually increase proportional to the number of people squared.</p><p class="calibre_1">These are different “variables,” and it matters which one we increase. The correct way to express this is with two variables. If there are <span class="italic">M</span> men and <span class="italic">W</span> women, then our meet and greet takes O(M*W) time.</p><p class="calibre_1">What if the women all knew each other, but the men knew no one at all? We would then say that the meet and greet is O(M<sup class="calibre11"><small class="calibre12">2</small></sup> + M*W). Note that we do not drop that extra M*W term; it’s a different variable, and it matters.</p><p class="calibre_12"><span class="italic"><span class="bold">Why This Matters (And Why It Doesn’t)</span></span></p><p class="calibre_31">Let’s suppose that we have two functions which process some data. The function <span class="italic">foo</span> takes O(N) time and the function <span class="italic">bar</span> takes O(N<sup class="calibre11"><small class="calibre12">2</small></sup>) time. On a given data set (for example, a specific list of people), which one will be faster?</p><p class="calibre_1">We don’t know, actually.</p><p class="calibre_1">The runtime of foo will increase proportionally to O(N) and the runtime of bar will increase proportionally to O(N<sup class="calibre11"><small class="calibre12">2</small></sup>). So, eventually, the O(N<sup class="calibre11"><small class="calibre12">2</small></sup>) line should exceed the O(N) time.</p><p class="calibre_2"><img src="images/00002.jpg" class="calibre_59"/><br class="calibre1"/></p><p class="calibre_1">However, we can’t make any determinations on a particular data set. The O(N<sup class="calibre11"><small class="calibre12">2</small></sup>) could be faster on smaller data sets; it might not have yet exceeded the O(N) line. Plus, even on very large data—after this “overtaking” occurs—there could be exceptions. Maybe, when N is divisible by 1000, the <span class="italic">bar</span> code will hit a special case and suddenly operate very quickly. We just don’t know.</p><p class="calibre_1">This doesn’t make big O useless; we just have to be very careful about how we apply it.</p><p class="calibre_1">Big O allows us to say things like, “In general, as our data set grows in size, this algorithm will be much, much faster than this other one.” It also allows us to say, “You want to run this O(N<sup class="calibre11"><small class="calibre12"><span class="calibre14">2</span></small></sup>) algorithm, and N is the number of files on our network? Sorry, that’s just not going to work.” That matters—a lot.</p><p class="calibre_1">Moreover, it gives us a language for expressing efficiency that isn’t reliant on the system architecture or the technologies used. Without big O, we’d likely have to discuss efficiency in terms of seconds, which has little meaning when you are on a different system.</p><p class="calibre_12"><span class="italic"><span class="bold">Logs and Big O</span></span></p><p class="calibre_31">You might notice, as you’re doing problems, that we (and others) describe problems as O(log(N)) or O(lg(N)), but we aren’t particularly concerned about specifying whether we mean log<sub class="calibre15"><small class="calibre12">2</small></sub>(N) or log<sub class="calibre15"><small class="calibre12">10</small></sub>(N). That’s because it doesn’t matter. The difference between one log and another is just a constant factor: log<sub class="calibre15"><small class="calibre12"><span class="calibre14">b</span></small></sub>(n) equals log<sub class="calibre15"><small class="calibre12"><span class="calibre14">k</span></small></sub>(n) / log<sub class="calibre15"><small class="calibre12"><span class="calibre14">k</span></small></sub>(b). Since big O time doesn’t care about constant factors, we don’t need to care about what our log base is.</p><p class="calibre_12"><span class="italic"><span class="bold">Big O Space and More</span></span></p><p class="calibre_31">The concept of big O can be used for much more than runtime. In fact, very commonly it is used to describe how much memory an algorithm uses.</p><p class="calibre_1">For example, suppose I have an algorithm that creates and initializes an NxN matrix:</p><div class="calibre_15"> </div><ol class="calibre_38"><li value="1" class="calibre_60"><span class="calibre5"><tt class="calibre10">int[][] a = new int[N][N]; /* NxN matrix */</tt></span></li><li value="2" class="calibre_60"><span class="calibre5"><tt class="calibre10">for i from 0 to N {</tt></span></li><li value="3" class="calibre_60"><span class="calibre5"><tt class="calibre10">   for j from 0 to N {</tt></span></li><li value="4" class="calibre_60"><span class="calibre5"><tt class="calibre10">     a[i][j] = i + j</tt></span></li><li value="5" class="calibre_60"><span class="calibre5"><tt class="calibre10">   }</tt></span></li><li value="6" class="calibre_60"><span class="calibre5"><tt class="calibre10">}</tt></span></li></ol><p class="calibre_31">This algorithm takes O(N<sup class="calibre11"><small class="calibre12">2</small></sup>) time and O(N<sup class="calibre11"><small class="calibre12">2</small></sup>) space.</p><blockquote class="calibre_23"><span class="italic">Note: If you’ve taken an algorithms class, you might remember that, technically, big O refers to an upper bound. Anything that is O(N) could also be said to be O(N<sup class="calibre11"><small class="calibre12"><span class="calibre14"><span class="italic">2</span></span></small></sup>). To describe the exact runtime, we should be using big-theta.</span><br class="calibre1"/>
<br class="calibre1"/>
<span class="italic">That is true, by the official mathematical definition of big O. However, outside of an algorithms class, this distinction has been forgotten about.</span></blockquote><p class="calibre_61"><span class="italic"><span class="bold">Sample Problems</span></span></p><p class="calibre_31">Now, let’s move on to some examples (in pseudocode). Can you find the runtime of each of these problems?</p><p class="calibre_12"><span class="italic">Example 1</span></p><p class="calibre_31">Consider the following code to print the numbers from 0 to n.</p><div class="calibre_15"> </div><ol class="calibre_38"><li value="1" class="calibre_60"><span class="calibre5"><tt class="calibre10">for i from 0 to n {</tt></span></li><li value="2" class="calibre_60"><span class="calibre5"><tt class="calibre10">   print i</tt></span></li><li value="3" class="calibre_60"><span class="calibre5"><tt class="calibre10">}</tt></span></li></ol><p class="calibre_31">This is said to be O(n) time. That is, if we were to run this code for many different values of n, the runtime would increase at a rate proportional to n.</p><p class="calibre_12"><span class="italic">Example 2</span></p><p class="calibre_31">What about this code?</p><div class="calibre_15"> </div><ol class="calibre_38"><li value="1" class="calibre_60"><span class="calibre5"><tt class="calibre10">sum = 0</tt></span></li><li value="2" class="calibre_60"><span class="calibre5"><tt class="calibre10">for i from 0 to n {</tt></span></li><li value="3" class="calibre_60"><span class="calibre5"><tt class="calibre10">   sum = sum + i</tt></span></li><li value="4" class="calibre_60"><span class="calibre5"><tt class="calibre10">   for j from 0 to n {</tt></span></li><li value="5" class="calibre_60"><span class="calibre5"><tt class="calibre10">     sum = sum + j</tt></span></li><li value="6" class="calibre_60"><span class="calibre5"><tt class="calibre10">   }</tt></span></li><li value="7" class="calibre_60"><span class="calibre5"><tt class="calibre10">}</tt></span></li></ol><p class="calibre_31">This is O(N<sup class="calibre11"><small class="calibre12">2</small></sup>) time. There are two for-loops, each running from 0 to n. How many times does line 5 get executed? O(N<sup class="calibre11"><small class="calibre12">2</small></sup>). The time for this code to run will increase at a rate of O(N<sup class="calibre11"><small class="calibre12">2</small></sup>).</p><p class="calibre_12"><span class="italic">Example 3</span></p><p class="calibre_31">The code below uses two variables. What is its running time?</p><div class="calibre_15"> </div><ol class="calibre_38"><li value="1" class="calibre_60"><span class="calibre5"><tt class="calibre10">/* Assume A and B are both arrays.*/</tt></span></li><li value="2" class="calibre_60"><span class="calibre5"><tt class="calibre10">for i from 0 to A.length {</tt></span></li><li value="3" class="calibre_60"><span class="calibre5"><tt class="calibre10">   int j = 0;</tt></span></li><li value="4" class="calibre_60"><span class="calibre5"><tt class="calibre10">   while (a[i] != b[j]) {</tt></span></li><li value="5" class="calibre_60"><span class="calibre5"><tt class="calibre10">     print a[i]</tt></span></li><li value="6" class="calibre_60"><span class="calibre5"><tt class="calibre10">     j = j + 1</tt></span></li><li value="7" class="calibre_60"><span class="calibre5"><tt class="calibre10">   }</tt></span></li><li value="8" class="calibre_60"><span class="calibre5"><tt class="calibre10">}</tt></span></li></ol><p class="calibre_31">This is said to be O(a*b), where a is the length of A and b is the length of B. Although the inner while loop may sometimes terminate early (having found a<tt class="calibre10">[i]</tt>), the expected case is that it will iterate through roughly all of B.</p><p class="calibre_12"><span class="italic">Example 4</span></p><p class="calibre_31">Here is a more challenging example.</p><div class="calibre_15"> </div><ol class="calibre_38"><li value="1" class="calibre_60"><span class="calibre5"><tt class="calibre10">int i = N;</tt></span></li><li value="2" class="calibre_60"><span class="calibre5"><tt class="calibre10">while i &gt;= 1 {</tt></span></li><li value="3" class="calibre_60"><span class="calibre5"><tt class="calibre10">   print i</tt></span></li><li value="4" class="calibre_60"><span class="calibre5"><tt class="calibre10">   i = i / 2</tt></span></li><li value="5" class="calibre_60"><span class="calibre5"><tt class="calibre10">}</tt></span></li></ol><p class="calibre_31">We need to think about what this for loop will do. This for loop will do something (print a value) and then continuously divide by 2 until it gets below 1.</p><p class="calibre_1">How many times can we divide N by 2 until we get below 1 and the while loop terminates? If we approached this in reverse, we could say: how many times can we multiply 1 by 2 until we get to N? This would be the value x, where 2<sup class="calibre11"><small class="calibre12">x</small></sup> = n. This for loop, therefore, iterates x times.</p><p class="calibre_1">Now we just need to solve for x:</p><blockquote class="calibre_23"><tt class="calibre10">2<sup class="calibre11"><small class="calibre12"><tt class="calibre10">x</tt></small></sup> = n</tt></blockquote><blockquote class="calibre_5"><tt class="calibre10">log(2<sup class="calibre11"><small class="calibre12"><tt class="calibre10">x</tt></small></sup>)</tt><span class="calibre6"><tt class="calibre10"> = </tt></span><tt class="calibre10">log(n)</tt></blockquote><blockquote class="calibre_5"><span class="calibre6"><tt class="calibre10">x </tt></span><tt class="calibre10">log(2)</tt><span class="calibre6"><tt class="calibre10"> = </tt></span><tt class="calibre10">log(n)</tt></blockquote><blockquote class="calibre_5"><span class="calibre6"><tt class="calibre10">x = </tt></span><tt class="calibre10">log(n)</tt><span class="calibre6"><tt class="calibre10"> / </tt></span><tt class="calibre10">log(2)</tt></blockquote><p class="calibre_31">So, this code operates in <tt class="calibre10">O(log(n))</tt> time.</p><p class="calibre_1">This is a good thing to remember: if something continuously divides in half, it is O(log(N)) time.</p><p class="calibre_1"><span class="calibre4"><span class="italic">Recursion</span></span></p><p class="calibre_14">If a function can call other functions, then it can call itself. This is recursion.</p><p class="calibre_1">Recursion can be a useful strategy to solve a large number of problems. It works well when the solution to a problem can be defined in terms of the solutions to subproblems.</p><p class="calibre_1">For example, consider the <tt class="calibre10">factorial</tt> problem. What is n! (n factorial)? n! is n * (n-1) * (n-2) * … * 1. We could also say that n! is n * (n-1)!.</p><p class="calibre_1">This leads to an extremely short bit of code to compute n!.</p><div class="calibre_15"> </div><ol class="calibre_38"><li value="1" class="calibre_60"><span class="calibre5"><tt class="calibre10">int factorial(int n) {</tt></span></li><li value="2" class="calibre_60"><span class="calibre5"><tt class="calibre10">   if (n == 0 or n == 1) { /* base case */</tt></span></li><li value="3" class="calibre_60"><span class="calibre5"><tt class="calibre10">     return 1;</tt></span></li><li value="4" class="calibre_60"><span class="calibre5"><tt class="calibre10">   } else {</tt></span></li><li value="5" class="calibre_60"><span class="calibre5"><tt class="calibre10">     return n * factorial(n-1);</tt></span></li><li value="6" class="calibre_60"><span class="calibre5"><tt class="calibre10">   }</tt></span></li><li value="7" class="calibre_60"><span class="calibre5"><tt class="calibre10">}</tt></span></li></ol><p class="calibre_31">The base case (or terminating condition) is extremely important. Without it, the function would run forever.</p><p class="calibre_1">Here’s another example of a recursive function. This computes the nth fibonacci number. As you may recall, the nth fibonacci number, <tt class="calibre10">f(n)</tt>, is <tt class="calibre10">f(n-1) + f(n-2)</tt>.</p><div class="calibre_15"> </div><ol class="calibre_38"><li value="1" class="calibre_60"><span class="calibre5"><tt class="calibre10">int fibonacci(int n) {</tt></span></li><li value="2" class="calibre_60"><span class="calibre5"><tt class="calibre10">   if (n == 0) {</tt></span></li><li value="3" class="calibre_60"><span class="calibre5"><tt class="calibre10">     return 0;</tt></span></li><li value="4" class="calibre_60"><span class="calibre5"><tt class="calibre10">   } else if (n == 1) {</tt></span></li><li value="5" class="calibre_60"><span class="calibre5"><tt class="calibre10">     return 1;</tt></span></li><li value="6" class="calibre_60"><span class="calibre5"><tt class="calibre10">   } else {</tt></span></li><li value="7" class="calibre_60"><span class="calibre5"><tt class="calibre10">     return fibonacci(n-1) + fibonacci(n-2);</tt></span></li><li value="8" class="calibre_60"><span class="calibre5"><tt class="calibre10">   }</tt></span></li><li value="9" class="calibre_60"><span class="calibre5"><tt class="calibre10">}</tt></span></li></ol><p class="calibre_31">This is a natural function to implement recursively, as the nth fibonacci numbers are defined by their smaller problems.</p><p class="calibre_12"><span class="italic"><span class="bold">Memory Usage</span></span></p><p class="calibre_31">Any problem that can be solved recursively can also be solved iteratively (non-recursively), although sometimes doing so is much more complicated. However, recursion comes with a drawback, which is memory usage.</p><p class="calibre_1">Recall this example:</p><div class="calibre_15"> </div><ol class="calibre_38"><li value="1" class="calibre_60"><span class="calibre5"><tt class="calibre10">int factorial(int n) {</tt></span></li><li value="2" class="calibre_60"><span class="calibre5"><tt class="calibre10">   if (n == 1) { /* base case */</tt></span></li><li value="3" class="calibre_60"><span class="calibre5"><tt class="calibre10">     return 1;</tt></span></li><li value="4" class="calibre_60"><span class="calibre5"><tt class="calibre10">   } else {</tt></span></li><li value="5" class="calibre_60"><span class="calibre5"><tt class="calibre10">     return n * factorial(n-1);</tt></span></li><li value="6" class="calibre_60"><span class="calibre5"><tt class="calibre10">   }</tt></span></li><li value="7" class="calibre_60"><span class="calibre5"><tt class="calibre10">}</tt></span></li></ol><p class="calibre_31">This takes O(N) time, and will on any solution. What is its memory usage? Its memory usage will be O(N) too (assuming no fancy optimizations by the compiler).</p><p class="calibre_1">The method factorial(n) calls factorial(n-1), which calls factorial(n-2), and so on. Note that factorial(n) does not complete until factorial(n-1) completes, which in turn doesn’t complete until factorial(n-2).</p><p class="calibre_1">Therefore, at one point in time, we have n functions in operation at once, on the “call stack.”</p><blockquote class="calibre_23"><span class="calibre6"><tt class="calibre10">factorial(0)</tt></span></blockquote><blockquote class="calibre_5"><span class="calibre6"><tt class="calibre10">factorial(1)</tt></span></blockquote><blockquote class="calibre_5"><span class="calibre6"><tt class="calibre10">...</tt></span></blockquote><blockquote class="calibre_5"><span class="calibre6"><tt class="calibre10">factorial(n-1)</tt></span></blockquote><blockquote class="calibre_5"><span class="calibre6"><tt class="calibre10">factorial(n)</tt></span></blockquote><p class="calibre1" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_31">Each one of those takes up some memory. Therefore, at one point in time, n chunks of memory are being used. This means that this program, when implemented recursively, is O(N) time and O(N) memory.</p><p class="calibre_1">This is the drawback of recursion: the recursive calls take up memory.</p><div class="mbp_pagebreak" id="calibre_pb_108"></div>
</body></html>
