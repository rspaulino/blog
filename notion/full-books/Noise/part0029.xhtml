<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>part0029</title>
<link rel="stylesheet" type="text/css" href="stylesheet.css" />
</head>
<body>
<div id="page_210" class="s6B">
<a href="part0003.xhtml#a2XK">CHAPTER 18</a>
</div>
<div class="s6T">
<a href="part0003.xhtml#a2XK">Better Judges for Better Judgments</a>
</div>
<div class="s4M">
<span class="s2WY">T</span>
hus far, we have mostly spoken of human judges without distinguishing among them. Yet it is obvious that in any task that requires judgment, some people will perform better than others will. Even a wisdom-of-crowds aggregate of judgments is likely to be better if the crowd is composed of more able people. An important question, then, is how to identify these better judges.</div>
<div class="s4P">Three things matter. Judgments are both less noisy and less biased when those who make them are well trained, are more intelligent, and have the right cognitive style. In other words: good judgments depend on what you know, how well you think, and <span class="s2WT-0">how</span>
 you think. Good judges tend to be experienced and smart, but they also tend to be actively open-minded and willing to learn from new information.</div>
<div class="s7D">Experts and Respect-Experts</div>
<div class="s4M">It is almost tautological to say that the skill of judges affects the quality of their judgments. For instance, radiologists who are skilled are more likely to diagnose pneumonia correctly, and in forecasting world events there are “superforecasters” who reliably out-predict their less-than-super peers. If you assemble a group of lawyers who are true specialists in some area of law, they are likely to make similar, and good, predictions about the outcome of common legal disputes in court. Highly skilled people are less noisy, and they also show less bias.</div>
<div class="s4P">These people are true experts at the tasks in question. Their superiority over others is verifiable, thanks to the availability of <span id="page_211"></span>
outcome data. In principle at least, we can choose a doctor, forecaster, or lawyer according to how often they have been right in the past. (For obvious reasons, this approach may be difficult in practice; we don’t recommend that you attempt to subject your family practitioner to a proficiency exam.)</div>
<div class="s4P">As we have also noted, many judgments are not verifiable. Within certain boundaries, we cannot easily know or uncontroversially define the true value at which judgments are aiming. Underwriting and criminal sentencing fall in this category, as do wine tasting, essay grading, book and movie reviewing, and innumerable other judgments. Yet some professionals in these domains come to be called experts. The confidence we have in these experts’ judgment is entirely based on the respect they enjoy from their peers. We call them <span class="s2WT-0">respect-experts.</span>
</div>
<div class="s4P">The term <span class="s2WT-0">respect-expert</span>
 is not meant to be disrespectful. The fact that some experts are not subject to an evaluation of the accuracy of their judgments is not a criticism; it is a fact of life in many domains. Many professors, scholars, and management consultants are respect-experts. Their credibility depends on the respect of their students, peers, or clients. In all these fields, and many more, the judgments of one professional can be compared only with those of her peers.</div>
<div class="s4P">In the absence of true values to determine who is right or wrong, we often value the opinion of respect-experts even when they disagree with one another. Picture, for instance, a panel on which several political analysts have sharply different perspectives on what caused a diplomatic crisis and how it will unfold. (This disagreement is not unusual; it would not be a very interesting panel if they all agreed.) All the analysts believe that there is a correct view and that their own view is the one closest to it. As you listen, you may find several of the analysts equally impressive and their arguments equally convincing. You cannot know then which of them is correct (and you may not even know later, if their analyses are not formulated as clearly verifiable predictions). You know that at least some of the analysts are wrong, because they are in disagreement. Yet you respect their expertise.</div>
<div class="s4P">Or consider a different set of experts, not making predictions at all. Three moral philosophers, all of them well trained, are gathered in a room. One of them follows Immanuel Kant; another, <span id="page_212"></span>
Jeremy Bentham; and a third, Aristotle. With respect to what morality requires, they disagree intensely. The issue might involve whether and when it is legitimate to lie, or the rights of animals, or the goal of criminal punishment. You listen closely. You might admire the clarity and precision of their thinking. You tend to agree with one philosopher, but you respect them all.</div>
<div class="s4P">Why do you do that? More generally, how do people who are themselves respected for the quality of their judgment decide to trust someone as an expert when there is no data to establish expertise objectively? What makes a respect-expert?</div>
<div class="s4P">Part of the answer is the existence of shared norms, or professional doctrine. Experts often obtain professional qualifications from professional communities and receive training and supervision in their organizations. Doctors who complete their residency and young lawyers who learn from a senior partner do not just learn the technical tools of their trade; they are trained to use certain methods and follow certain norms.</div>
<div class="s4P">Shared norms give professionals a sense of which inputs should be taken into account and how to make and justify their final judgments. In the insurance company, for instance, claims adjusters had no difficulty agreeing on and describing the relevant considerations that should be included in a checklist to assess a claim.</div>
<div class="s4P">This agreement, of course, did not stop the claims adjusters from varying widely in their claims assessments, because doctrine does not fully specify how to proceed. It is not a recipe that can be mechanically followed. Instead, doctrine leaves room for interpretation. Experts still produce judgments, not computations. That is why noise inevitably occurs. Even identically trained professionals who agree on the doctrine they are applying will drift away from one another in their application of it.</div>
<div class="s4P">Beyond a knowledge of shared norms, experience is necessary, too. You can be a young prodigy if your specialty is chess, concert piano, or throwing the javelin, because results validate your level of performance. But underwriters, fingerprint examiners, or judges usually need some years of experience for credibility. There are no young prodigies in underwriting.</div>
<div class="s4P">Another characteristic of respect-experts is their ability to make and explain their judgments with confidence. We tend to put <span id="page_213"></span>
more trust in people who trust themselves than we do in those who show their doubts. The confidence heuristic points to the fact that in a group, confident people have more weight than others, even if they have no reason to be confident. Respect-experts excel at constructing coherent stories. Their experience enables them to recognize patterns, to reason by analogy with previous cases, and to form and confirm hypotheses quickly. They easily fit the facts they see into a coherent story that inspires confidence.</div>
<div class="s7D">Intelligence</div>
<div class="s4M">Training, experience, and confidence enable respect-experts to command trust. But these attributes do not guarantee the quality of their judgments. How can we know which experts are likely to make good judgments?</div>
<div class="s4P">There is good reason to believe that general intelligence is likely to be associated with better judgment. Intelligence is correlated with good performance in virtually all domains. All other things being equal, it is associated not only with higher academic achievement but also with higher job performance.</div>
<div class="s4P">Many debates and misunderstandings arise in discussions of measures of intelligence or of general mental ability (GMA, the term now used in preference to intelligence quotient, or IQ). There are lingering misconceptions about the innate nature of intelligence; in fact, tests measure developed abilities, which are partly a function of heritable traits and partly influenced by the environment, including educational opportunities. Many people also have concerns about the adverse impact of GMA-based selection on identifiable social groups and the legitimacy of using GMA tests for selection purposes.</div>
<div class="s4P">We need to separate these concerns about the use of tests from the reality of their predictive value. Since the US Army started using tests of mental ability more than a century ago, thousands of studies have measured the link between cognitive test scores and subsequent performance. The message that emerges from this mass of research is unambiguous. As one review put it, “GMA predicts both occupational level attained and performance within one’s chosen occupation and does so better than any other ability, trait, or disposition and better than job experience.” Of course, other <span id="page_214"></span>
cognitive abilities matter too (more on this later). So do many personality traits—including conscientiousness and <span class="s2WT-0">grit,</span>
 defined as perseverance and passion in the pursuit of long-term goals. And yes, there are various forms of intelligence that GMA tests do not measure, such as practical intelligence and creativity. Psychologists and neuroscientists distinguish between crystallized intelligence, the ability to solve problems by relying on a store of knowledge about the world (including arithmetical operations), and fluid intelligence, the ability to solve novel problems.</div>
<div class="s4P">Yet for all its crudeness and limitations, GMA, as measured by standardized tests containing questions on verbal, quantitative, and spatial problems, remains by far the best single predictor of important outcomes. As the previously mentioned review adds, the predictive power of GMA is “larger than most found in psychological research.” The strength of the association between general mental ability and job success increases, quite logically, with the complexity of the job in question: intelligence matters more for rocket scientists than it does for those with simpler tasks. For jobs of high complexity, the correlations that can be observed between standardized test scores and job performance are in the .50 range (PC = 67%). As we have noted, a correlation of .50 indicates a very strong predictive value by social-science standards.</div>
<div class="s4P">Especially in discussions of skilled professional judgments, an important and frequent objection to the relevance of intelligence measures is that all those who make such judgments are likely to be high-GMA individuals. Doctors, judges, or senior underwriters are much more educated than the general population and highly likely to score much higher on any measure of cognitive ability. You might reasonably believe that high GMA makes little difference among them—that it is merely the entry ticket into the pool of high achievers, not the source of achievement differences within that pool.</div>
<div class="s4P">This belief, although widespread, is incorrect. No doubt the range of GMAs found in a given occupation is wider at the bottom of the range of occupations than at the top: there are high-GMA individuals in lower-level occupations but almost no people with below-average GMA among lawyers, chemists, or engineers. From that perspective, therefore, high mental ability is apparently a necessary condition for gaining access to high-status professions.</div>
<div id="page_215" class="s4P">However, this measure fails to capture differences in achievement <span class="s2WT-0">within</span>
 these groups. Even among the top 1% of people as measured by cognitive ability (evaluated at age thirteen), exceptional outcomes are strongly correlated with GMA. Compared with those who are in the bottom quartile of this top 1%, those who are in the top quartile are two to three times more likely to earn a doctoral-level degree, publish a book, or be granted a patent. In other words, not only does the difference in GMA matter between the 99th percentile and the 80th or 50th, but it still matters—a lot!—between the 99.88th percentile and the 99.13th.</div>
<div class="s4P">In another striking illustration of the link between ability and outcomes, a 2013 study focused on the CEOs of Fortune 500 companies and the 424 American billionaires (the top 0.0001% of Americans by wealth). It found, predictably, that these hyper-elite groups are composed of people drawn from the most intellectually able. But the study also found that <span class="s2WT-0">within</span>
 these groups, higher education and ability levels are related to higher compensation (for CEOs) and net worth (for billionaires). Incidentally, famous college dropouts who become billionaires, such as Steve Jobs, Bill Gates, and Mark Zuckerberg, are the trees that hide the forest: whereas about one-third of American adults have earned a college degree, 88% of billionaires did so.</div>
<div class="s4P">The conclusion is clear. GMA contributes significantly to the quality of performance in occupations that require judgment, even within a pool of high-ability individuals. The notion that there is a threshold beyond which GMA ceases to make a difference is not supported by the evidence. This conclusion in turn strongly suggests that if professional judgments are unverifiable but assumed to reach for an invisible bull’s-eye, then the judgments of high-ability people are more likely to be close. If you must pick people to make judgments, picking those with the highest mental ability makes a lot of sense.</div>
<div class="s4P">But this line of reasoning has an important limitation. Since you cannot give standardized tests to everyone, you will have to guess who the higher-GMA people are. And high GMA improves performance on many fronts, including the ability to convince others that you’re right. People of high mental ability are more likely than others to make better judgments and to be true experts, but they are also more likely to impress their peers, earn others’ trust, <span id="page_216"></span>
and become respect-experts in the absence of any reality feedback. Medieval astrologers must have been among the highest-GMA people of their time.</div>
<div class="s4P">It can be sensible to place your trust in people who look and sound intelligent and who can articulate a compelling rationale for their judgments, but this strategy is insufficient and may even backfire. Are there, then, other ways to identify real experts? Do people with the best judgment have other recognizable traits?</div>
<div class="s7D">Cognitive Style</div>
<div class="s4M">Regardless of mental ability, people differ in their <span class="s2WT-0">cognitive style,</span>
 or their approach to judgment tasks. Many instruments have been developed to capture cognitive styles. Most of these measures correlate with GMA (and with one another), but they measure different things.</div>
<div class="s4P">One such measure is the <span class="s2WT-0">cognitive reflection test</span>
 (CRT), made famous by the now-ubiquitous question about the ball and the bat: “A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?” Other questions that have been proposed to measure cognitive reflection include this one: “If you’re running a race and you pass the person in second place, what place are you in?” CRT questions attempt to measure how likely people are to override the first (and wrong) answer that comes to mind (“ten cents” for the ball-and-bat question, and “first” for the race example). Lower CRT scores are associated with many real-world judgments and beliefs, including belief in ghosts, astrology, and extrasensory perception. The scores predict whether people will fall for blatantly inaccurate “fake news.” They are even associated with how much people will use their smartphones.</div>
<div class="s4P">The CRT is seen by many as one instrument to measure a broader concept: the propensity to use reflective versus impulsive thought processes. Simply put, some people like to engage in careful thought, whereas others, faced with the same problem, tend to trust their first impulses. In our terminology, the CRT can be seen as a measure of people’s propensity to rely on slow, System 2 thinking rather than on fast, System 1 thinking.</div>
<div class="s4P">Other self-assessments have been developed to measure this <span id="page_217"></span>
propensity (and all these tests are, of course, intercorrelated). The need-for-cognition scale, for instance, asks people how much they like to think hard about problems. To score high on the scale, you would have to agree that “I tend to set goals that can be accomplished only by expending considerable mental effort” and disagree with “Thinking is not my idea of fun.” People with a high need for cognition tend to be less susceptible to known cognitive biases. Some more bizarre associations have been reported, too: if you avoid movie reviews with a spoiler alert, you probably have a high need for cognition; those who are low on the need-for-cognition scale prefer spoiled stories.</div>
<div class="s4P">Because that scale is a self-assessment and because the socially desirable answer is fairly obvious, the scale raises fair questions. Someone who is trying to impress is hardly likely to endorse the statement “Thinking is not my idea of fun.” For that reason, other tests try to measure skills instead of using self-descriptions.</div>
<div class="s4P">One example is the Adult Decision Making Competence scale, which measures how prone people are to make typical errors in judgment like overconfidence or inconsistency in risk perceptions. Another is the Halpern Critical Thinking Assessment, which focuses on critical thinking skills, including both a disposition toward rational thinking and a set of learnable skills. Taking this assessment, you would be asked questions like this: “Imagine that a friend asks you for advice about which of two weight-loss programs to choose. Whereas one program reports that clients lose an average of twenty-five pounds, the other program reports that they lose an average of thirty pounds. What questions would you like to have answered before choosing one of the programs?” If you answered, for instance, that you would want to know how many people lost this much weight and whether they maintained that weight loss for a year or more, you would score points for applying critical thinking. People who score well on the Adult Decision Making Competence scale or on the Halpern assessment seem to make better judgments in life: they experience fewer adverse life events driven by bad choices, such as needing to pay late fees for a movie rental and experiencing an unwanted pregnancy.</div>
<div class="s4P">It seems sensible to assume that all these measures of cognitive style and skill—and many others—generally predict <span id="page_218"></span>
judgment. Their relevance seems, however, to vary with the task. When Uriel Haran, Ilana Ritov, and Barbara Mellers looked for the cognitive styles that might predict forecasting ability, they found that the need for cognition did not predict who would work harder to seek additional information. They also did not find that the need for cognition was reliably associated with higher performance.</div>
<div class="s4P">The only measure of cognitive style or personality that they found to predict forecasting performance was another scale, developed by psychology professor Jonathan Baron to measure “actively open-minded thinking.” To be actively open-minded is to actively search for information that contradicts your preexisting hypotheses. Such information includes the dissenting opinions of others and the careful weighing of new evidence against old beliefs. Actively open-minded people agree with statements like this: “Allowing oneself to be convinced by an opposing argument is a sign of good character.” They disagree with the proposition that “changing your mind is a sign of weakness” or that “intuition is the best guide in making decisions.”</div>
<div class="s4P">In other words, while the cognitive reflection and need for cognition scores measure the propensity to engage in slow and careful thinking, actively open-minded thinking goes beyond that. It is the humility of those who are constantly aware that their judgment is a work in progress and who yearn to be corrected. We will see in <a href="part0032.xhtml">chapter 21</a>
 that this thinking style characterizes the very best forecasters, who constantly change their minds and revise their beliefs in response to new information. Interestingly, there is some evidence that actively open-minded thinking is a teachable skill.</div>
<div class="s4P">We do not aim here to draw hard-and-fast conclusions about how to pick individuals who will make good judgments in a given domain. But two general principles emerge from this brief review. First, it is wise to recognize the difference between domains in which expertise can be confirmed by comparison with true values (such as weather forecasting) and domains that are the province of respect-experts. A political analyst may sound articulate and convincing, and a chess grandmaster may sound timid and unable to explain the reasoning behind some of his moves. Yet we probably should treat the professional judgment of the former with more skepticism than that of the latter.</div>
<div class="s4P">Second, some judges are going to be better than their equally <span id="page_219"></span>
qualified and experienced peers. If they are better, they are less likely to be biased or noisy. Among many things that explain these differences, intelligence and cognitive style matter. Although no single measure or scale unambiguously predicts judgment quality, you may want to look for the sort of people who actively search for new information that could contradict their prior beliefs, who are methodical in integrating that information into their current perspective, and who are willing, even eager, to change their minds as a result.</div>
<div class="s4P">The personality of people with excellent judgment may not fit the generally accepted stereotype of a decisive leader. People often tend to trust and like leaders who are firm and clear and who seem to know, immediately and deep in their bones, what is right. Such leaders inspire confidence. But the evidence suggests that if the goal is to reduce error, it is better for leaders (and others) to remain open to counterarguments and to know that they might be wrong. If they end up being decisive, it is at the end of a process, not at the start.</div>
<div class="s84">Speaking of Better Judges</div>
<div class="s86">
<span class="class-2">“You are an expert. But are your judgments verifiable, or are you a respect-expert?”</span>
</div>
<div class="s88">
<span class="class-2">“We have to choose between two opinions, and we know nothing about these individuals’ expertise and track record. Let’s follow the advice of the more intelligent one.”</span>
</div>
<div class="s8A">
<span class="class-2">“Intelligence is only part of the story, however.</span>
 <span class="s2WT-3">How</span>
 <span class="class-2">people think is also important. Perhaps we should pick the most thoughtful, open-minded person, rather than the smartest one.”</span>
</div>
</body>
</html>
