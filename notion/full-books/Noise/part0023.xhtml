<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>part0023</title>
<link rel="stylesheet" type="text/css" href="stylesheet.css" />
</head>
<body>
<div id="page_151" class="s6B">
<a href="part0003.xhtml#a2YY">CHAPTER 13</a>
</div>
<div class="s6T">
<a href="part0003.xhtml#a2YY">Heuristics, Biases, and Noise</a>
</div>
<div class="s4M">
<span class="s2WY">T</span>
his book extends half a century of research on intuitive human judgment, the so-called heuristics and biases program. The first four decades of this research program were reviewed in <span class="s2WT-0">Thinking, Fast and Slow,</span>
 which explored the psychological mechanisms that explain both the marvels and the flaws of intuitive thinking. The central idea of the program was that people who are asked a difficult question use simplifying operations, called <span class="s2WT-0">heuristics</span>
. In general, heuristics, which are produced by fast, intuitive thinking, also known as <span class="s2WT-0">System 1 thinking,</span>
 are quite useful and yield adequate answers. But sometimes they lead to biases, which we have described as systematic, predictable errors of judgment.</div>
<div class="s4P">The heuristics and biases program focused on what people have in common, not on how they differ. It showed that the processes that cause judgment errors are widely shared. Partly because of this history, people who are familiar with the notion of psychological bias often assume that it always produces <span class="s2WT-0">statistical bias,</span>
 a term we use in this book to mean measurements or judgments that mostly deviate from the truth in the same direction. Indeed, psychological biases create statistical bias when they are broadly shared. However, psychological biases create system noise when judges are biased in different ways, or to a different extent. Whether they cause statistical bias or noise, of course, psychological biases always create error.</div>
<div class="s7D">Diagnosing Biases</div>
<div class="s4M">Judgment biases are often identified by reference to a true value. <span id="page_152"></span>
There is bias in predictive judgments if errors are mostly in one direction rather than the other. For instance, when people forecast how long it will take them to complete a project, the mean of their estimates is usually much lower than the time they will actually need. This familiar psychological bias is known as the <span class="s2WT-0">planning fallacy.</span>
</div>
<div class="s4P">Often, though, there is no true value to which judgments can be compared. Given how much we stressed that statistical bias can be detected only when the true value is known, you may wonder how psychological biases can be studied when the truth is unknown. The answer is that researchers confirm a psychological bias either by observing that a factor that should not affect judgment does have a statistical effect on it, or that a factor that should affect judgment does not.</div>
<div class="s4P">To illustrate this method, let us return to the shooting range analogy. Imagine that Teams A and B have taken their shots, and we are looking at the back of the target (<a href="part0023.xhtml#a2Z5">figure 12</a>
). In this example, you don’t know where the bull’s-eye is (the true value is unknown). Therefore, you don’t know how biased the two teams are relative to the center of the target. However, you are told that, in panel 1, the two teams were aiming at the same bull’s-eye, and that, in panel 2, Team A was aiming at one bull’s-eye and Team B at a different one.</div>
<div class="s4P">In spite of the absence of a target, both panels provide evidence of systematic bias. In panel 1, the shots of the two teams differ, although they should be identical. This pattern resembles what you would see in an experiment in which two groups of investors read business plans that are substantively identical but printed in a different font and on a different paper. If these irrelevant details make a difference in the investors’ judgment, there is psychological bias. We don’t know if the investors who were impressed by the sleek font and glossy paper are too positive or if those who read the rougher version are too negative. But we know their judgments are different, although they should not be.</div>
<div class="sE6">
<div class="sK">
<div class="sH-0"><img src="rsrc31N.jpg" alt="" id="a2Z5" class="sH-1" />
</div>
<div class="sE3">F<span class="s2WW">IGURE 12:</span>
 <span id="page_153"></span>
<span class="s2WT-0">A look at the back of the target in an experiment to test for bias</span>
</div>
</div>
</div>
<div class="s4P">Panel 2 illustrates the opposite phenomenon. Since the teams were aiming at different targets, the clusters of shots should be distinct, but they are centered on the same spot. For example, imagine that two groups of people are asked the same question you were asked in <a href="part0012.xhtml">chapter 4</a>
 about Michael Gambardi, but with a twist. One group is asked, as you were, to estimate the probability that Gambardi will still be in his job in two years; the other is asked to estimate the probability that he will still be in his job in three years. The two groups should reach different conclusions, because there are obviously more ways to lose your job in three years than in two. However, the evidence suggests that the probability estimates of the two groups will differ little, if at all. The answers should be clearly different, but they are not, suggesting that a factor that should influence judgments is ignored. (This psychological bias is called <span class="s2WT-0">scope insensitivity</span>
.)</div>
<div class="s4P">Systematic errors of judgment have been demonstrated in many fields, and the term <span class="s2WT-0">bias</span>
 is now used in many domains, including business, politics, policymaking, and law. As the word is commonly used, its meaning is broad. In addition to the cognitive definition we use here (referring to a psychological mechanism and to the error that this mechanism typically produces), the word is frequently used to suggest that someone is biased against a certain group (e.g., gender biases or racial biases). It can also mean that someone favors a particular conclusion, as when we read that someone is biased by a conflict of interest or by a political opinion. We include these types of bias in our discussion of the psychology of judgment errors because all psychological biases cause both statistical bias and noise.</div>
<div class="s4P">There is one usage to which we strongly object. In this usage, costly failures are attributed to unspecified “bias,” and acknowledgments of error are accompanied by promises to “work hard to eliminate biases in our decision making.” These statements mean nothing more than “mistakes were made” and “we will try hard to do better.” To be sure, some failures truly are caused by predictable errors associated with specific psychological biases, and we believe in the feasibility of interventions to reduce bias (and <span id="page_154"></span>
noise) in judgments and decisions. But blaming every undesirable outcome on biases is a worthless explanation. We recommend reserving the word <span class="s2WT-0">bias</span>
 for specific and identifiable errors and the mechanisms that produce them.</div>
<div class="s7D">Substitution</div>
<div class="s4M">To experience the heuristic process, please try your hand at answering the following question, which illustrates several essential themes of the heuristics and biases approach. As usual, you will get more from the example if you produce your own answers.</div>
<div class="s11B">Bill is thirty-three years old. He is intelligent but unimaginative, compulsive, and generally lifeless. In school, he was strong in mathematics but weak in social studies and humanities.</div>
<div class="s11D">
<span class="class-4">The following is a list of eight possibilities for Bill’s current situation.</span>
</div>
<div class="s11F">
<span class="s2WT-5">Please go over the list and select the two that you consider</span>
 <span class="class-4">most probable.</span>
</div>
<div class="sJT"><img src="rsrc31K.jpg" alt="" class="sJS" />
 <span class="s2WT-3">Bill is a physician who plays poker as a hobby.</span>
</div>
<div class="sT9"><img src="rsrc31K.jpg" alt="" class="sJS" />
 <span class="s2WT-3">Bill is an architect.</span>
</div>
<div class="sT9"><img src="rsrc31K.jpg" alt="" class="sJS" />
 <span class="s2WT-3">Bill is an accountant.</span>
</div>
<div class="sT9"><img src="rsrc31K.jpg" alt="" class="sJS" />
 <span class="s2WT-3">Bill plays jazz as a hobby.</span>
</div>
<div class="sT9"><img src="rsrc31K.jpg" alt="" class="sJS" />
 <span class="s2WT-3">Bill surfs as a hobby.</span>
</div>
<div class="sT9"><img src="rsrc31K.jpg" alt="" class="sJS" />
 <span class="s2WT-3">Bill is a reporter.</span>
</div>
<div class="sT9"><img src="rsrc31K.jpg" alt="" class="sJS" />
 <span class="s2WT-3">Bill is an accountant who plays jazz as a hobby.</span>
</div>
<div class="sT9"><img src="rsrc31K.jpg" alt="" class="sJS" />
 <span class="s2WT-3">Bill climbs mountains as a hobby.</span>
</div>
<div class="s121">
<span class="s2WT-0">Now, go back over the list and select the two categories where Bill</span>
 most resembles <span class="s2WT-0">a typical person in that category. You may pick the same or different categories as before.</span>
</div>
<div class="sS0">We are almost certain that you picked the same categories as <span id="page_155"></span>
highest in probability and in resemblance. The reason for our confidence is that multiple experiments have shown that people give identical answers to the two questions. But similarity and probability are actually quite different. For example, ask yourself, which of the following statements makes more sense?</div>
<div class="sJT"><img src="rsrc31K.jpg" alt="" class="sJS" />
 <span class="s2WT-3">Bill fits my idea of a person who plays jazz as a hobby.</span>
</div>
<div class="sJW"><img src="rsrc31K.jpg" alt="" class="sJS" />
 <span class="s2WT-3">Bill fits my idea of an accountant who plays jazz as a hobby.</span>
</div>
<div class="s4M">Neither of these statements is a good fit, but one of them is clearly less awful than the other. Bill has more in common with an accountant who plays jazz as a hobby than with a person who plays jazz as a hobby. Now consider this: which of the following is more probable?</div>
<div class="sJT"><img src="rsrc31K.jpg" alt="" class="sJS" />
 <span class="s2WT-3">Bill plays jazz as a hobby.</span>
</div>
<div class="sJW"><img src="rsrc31K.jpg" alt="" class="sJS" />
 <span class="s2WT-3">Bill is an accountant who plays jazz as a hobby.</span>
</div>
<div class="s4P">You may be tempted to pick the second answer, but logic won’t allow it. The probability that Bill plays jazz as a hobby <span class="s2WT-0">must be</span>
 higher than the probability of his being a jazz-playing accountant. Remember your Venn diagrams! If Bill is a jazz player and an accountant, he is certainly a jazz player. Adding detail to a description can only make it less probable, although it can make it more representative, and thus a better “fit,” as in the present case.</div>
<div class="s4P">The theory of judgment heuristics proposes that people will sometimes use the answer to an easier question in responding to the harder one. So, which question is more easily answered: “How similar is Bill to a typical amateur jazz player?” or “How probable is it that Bill is an amateur jazz player?” By acclamation, the similarity question is easier, which makes it likely that it was the one that people answer when asked to assess probability.</div>
<div class="s4P">You have now experienced the essential idea of the heuristics and biases program: a heuristic for answering a difficult question is to find the answer to an easier one. The substitution of one question for the other causes predictable errors, called psychological biases.</div>
<div id="page_156" class="s4P">This sort of bias is manifest in the Bill example. Errors are bound to occur when a judgment of similarity is substituted for a judgment of probability, because probability is constrained by a special logic. In particular, Venn diagrams apply only to probability, not to similarity. Hence the predictable logical error that many people make.</div>
<div class="s4P">For another example of a neglected statistical property, recall how you thought about the Gambardi question in <a href="part0012.xhtml">chapter 4</a>
. If you are like most people, your assessment of Michael Gambardi’s chances of success was based entirely on what the case told you about him. You then attempted to match his description to the image of a successful CEO.</div>
<div class="s4P">Did it occur to you to consider the probability that a randomly chosen CEO will still hold the same job two years later? Probably not. You can think of this <span class="s2WT-0">base-rate information</span>
 as a measure of the difficulty of surviving as a CEO. If this approach seems odd, consider how you would estimate the probability that a particular student would pass a test. Surely, the proportion of students who fail the test is relevant, as it gives you an indication of how difficult the test is. In the same manner, the base rate of CEO survival is relevant to the Gambardi problem. Both questions are examples of taking what we have called the outside view: when you take this view, you think of the student, or of Gambardi, as a member of a class of similar cases. You think statistically about the class, instead of thinking causally about the focal case.</div>
<div class="s4P">Taking the outside view can make a large difference and prevent significant errors. A few minutes of research would reveal that estimates of CEO turnover in US companies hover around 15% annually. This statistic suggests that the average incoming CEO has a roughly 72% probability of still being around after two years. Of course, this number is only a starting point, and the specifics of Gambardi’s case will affect your final estimate. But if you focused solely on what you were told about Gambardi, you neglected a key piece of information. (Full disclosure: We wrote the Gambardi case to illustrate noisy judgment; it took us weeks before we realized that it was also a prime example of the bias we describe here, which is called <span class="s2WT-0">base-rate neglect</span>
. Thinking of base rates is no more automatic for the authors of this book than for anyone else.)</div>
<div class="s4P">Substitution of one question for another is not restricted to <span id="page_157"></span>
similarity and probability. Another example is the replacement of a judgment of frequency by an impression of the ease with which instances come to mind. For example, the perception of the risk of airplane crashes or hurricanes rises briefly after well-publicized instances of such events. In theory, a judgment of risk should be based on a long-term average. In reality, recent incidents are given more weight because they come more easily to mind. Substituting a judgment of how easily examples come to mind for an assessment of frequency is known as the <span class="s2WT-0">availability heuristic.</span>
</div>
<div class="s4P">The substitution of an easy judgment for a hard one is not limited to these examples. In fact, it is very common. Answering an easier question can be thought of as a general-purpose procedure for answering a question that could stump you. Consider how we tend to answer each of the following questions by using its easier substitute:</div>
<div class="s12P">Do I believe in climate change?</div>
<div class="s12S">Do I trust the people who say it exists?</div>
<div class="s12U">Do I think this surgeon is competent?</div>
<div class="s12S">Does this individual speak with confidence and authority?</div>
<div class="s12U">Will the project be completed on schedule?</div>
<div class="s12S">Is it on schedule now?</div>
<div class="s12U">Is nuclear energy necessary?</div>
<div class="s12S">Do I recoil at the word <span class="s2WV-0">nuclear?</span>
</div>
<div class="s12U">Am I satisfied with my life as a whole?</div>
<div class="s132">What is my mood right now?</div>
<div class="s4P">Regardless of the question, substituting one question for another will lead to an answer that does not give different aspects of the evidence their appropriate weights, and incorrect weighting of the evidence inevitably results in error. For example, a full answer to a question about life satisfaction clearly requires consulting more than your current mood, but evidence suggests that mood is in fact overly weighted.</div>
<div class="s4P">In the same manner, substituting similarity for probability leads to neglect of base rates, which are quite properly irrelevant when judging similarity. And factors such as irrelevant variations in <span id="page_158"></span>
the aesthetics of the document that presents a business plan should be given little or no weight in assessing the value of a company. Any impact they have on the judgment is likely to reflect a misweighting of the evidence and will produce error.</div>
<div class="s7D">Conclusion Biases</div>
<div class="s4M">At a key moment in the development of the screenplay for <span class="s2WT-0">Return of the Jedi,</span>
 the third Star Wars film, George Lucas, the mastermind behind the series, had a heated debate with his great collaborator Lawrence Kasdan. Kasdan strongly advised Lucas, “I think you should kill Luke and have Leia take over.” Lucas promptly rejected the idea. Kasdan suggested that if Luke lived, another major character should die. Lucas again disagreed, adding, “You don’t go around killing people.” Kasdan responded with a heartfelt claim about the nature of cinema. He explained to Lucas that “the movie has more emotional weight if someone you love is lost along the way; the journey has more impact.”</div>
<div class="s4P">Lucas’s response was quick and unequivocal: “I don’t like that and I don’t believe that.”</div>
<div class="s4P">The thought process here looks quite different from the one you experienced when you thought about Bill, the jazz-playing accountant. Read Lucas’s answer again: “Not liking” precedes “Not believing.” Lucas had an automatic response to Kasdan’s suggestion. That response helped motivate his judgment (even if it turned out to be right).</div>
<div class="s4P">This example illustrates a different type of bias, which we call <span class="s2WT-0">conclusion bias,</span>
 or <span class="s2WT-0">prejudgment.</span>
 Like Lucas, we often start the process of judgment with an inclination to reach a particular conclusion. When we do that, we let our fast, intuitive System 1 thinking suggest a conclusion. Either we jump to that conclusion and simply bypass the process of gathering and integrating information, or we mobilize System 2 thinking—engaging in deliberate thought—to come up with arguments that support our prejudgment. In that case, the evidence will be selective and distorted: because of <span class="s2WT-0">confirmation bias</span>
 and <span class="s2WT-0">desirability bias</span>
, we will tend to collect and interpret evidence selectively to favor a judgment that, respectively, we already believe or wish to be true.</div>
<div id="page_159" class="s4P">People often come up with plausible rationalizations for their judgments and will actually think that they are the cause of their beliefs. A good test of the role of prejudgment is to imagine that the arguments seemingly supporting our belief are suddenly proven invalid. Kasdan, for instance, might well have pointed out to Lucas that “You don’t go around killing people” is hardly a compelling argument. The author of <span class="s2WT-0">Romeo and Juliet</span>
 would not have agreed with Lucas, and if the writers of <span class="s2WT-0">The Sopranos</span>
 and <span class="s2WT-0">Game of Thrones</span>
 had decided against killings, both shows would probably have been canceled in their first season. But we can bet that a strong counterargument wouldn’t have changed Lucas’s mind. Instead, he would have come up with other arguments to support his judgment. (For example, “Star Wars is different.”)</div>
<div class="s4P">Prejudgments are evident wherever we look. Like Lucas’s reaction, they often have an emotional component. The psychologist Paul Slovic terms this the <span class="s2WT-0">affect heuristic:</span>
 people determine what they think by consulting their feelings. We like most things about politicians we favor, and we dislike even the looks and the voices of politicians we dislike. That is one reason that smart companies work so hard to attach a positive affect to their brand. Professors often notice that in a year when they get high marks for teaching, students also give the course material a high rating. In a year when students don’t like the professor so much, they give a low rating to the identical assigned readings. The same mechanism is at work even when emotion is not involved: regardless of the true reasons for your belief, you will be inclined to accept any argument that appears to support it, even when the reasoning is wrong.</div>
<div class="s4P">A subtler example of a conclusion bias is the <span class="s2WT-0">anchoring effect,</span>
 which is the effect that an arbitrary number has on people who must make a quantitative judgment. In a typical demonstration, you might be presented with a number of items whose price is not easy to guess, such as an unfamiliar bottle of wine. You are asked to jot down the last two digits of your Social Security number and indicate whether you would pay that amount for the bottle. Finally, you are asked to state the maximum amount you would be willing to pay for it. The results show that anchoring on your Social Security number will affect your final buying price. In one study, people whose Social Security numbers generated a high anchor (more than eighty dollars) stated that they were willing to pay about three times <span id="page_160"></span>
more than those with a low anchor (less than twenty dollars).</div>
<div class="s4P">Clearly, your Social Security number should not have a large effect on your judgment about how much a bottle of wine is worth, but it does. Anchoring is an extremely robust effect and is often deliberately used in negotiations. Whether you’re haggling in a bazaar or sitting down for a complex business transaction, you probably have an advantage in going first, because the recipient of the anchor is involuntarily drawn to think of ways your offer could be reasonable. People always attempt to make sense of what they hear; when they encounter an implausible number, they automatically bring to mind considerations that would reduce its implausibility.</div>
<div class="s7D">Excessive Coherence</div>
<div class="s4M">Here is another experiment that will help you experience a third type of bias. You will read a description of a candidate for an executive position. The description consists of four adjectives, each written on a card. The deck of cards has just been shuffled. The first two cards have these two descriptors:</div>
<div class="s70">Intelligent, Persistent.</div>
<div class="s4P">It would be reasonable to suspend judgment until the information is complete, but this is not what has happened: you already have an evaluation of the candidate, and it is positive. This judgment simply happened. You had no control over the process, and suspending judgment was not an option.</div>
<div class="s4P">Next, you draw the last two cards. Here is the full description now:</div>
<div class="s70">Intelligent, Persistent, Cunning, Unprincipled.</div>
<div class="s4P">Your evaluation is no longer favorable, but it did not change enough. For comparison, consider the following description, which another shuffling of the deck could have produced:</div>
<div id="page_161" class="s70">Unprincipled, Cunning, Persistent, Intelligent.</div>
<div class="s4P">This second description consists of the same adjectives, and yet—because of the order in which they are introduced—it is clearly much less appealing than the first. The word <span class="s2WT-0">Cunning</span>
 was only mildly negative when it followed <span class="s2WT-0">Intelligent</span>
 and <span class="s2WT-0">Persistent,</span>
 because we still believed (without reason) that the executive’s intentions were good. Yet when it follows <span class="s2WT-0">Unprincipled,</span>
 the word <span class="s2WT-0">Cunning</span>
 is awful. In this context, persistence and intelligence are not positives anymore: they make a bad person even more dangerous.</div>
<div class="s4P">This experiment illustrates <span class="s2WT-0">excessive coherence:</span>
 we form coherent impressions quickly and are slow to change them. In this example, we immediately developed a positive attitude toward the candidate, in light of little evidence. Confirmation bias—the same tendency that leads us, when we have a prejudgment, to disregard conflicting evidence altogether—made us assign less importance than we should to subsequent data. (Another term to describe this phenomenon is the <span class="s2WT-0">halo effect,</span>
 because the candidate was evaluated in the positive “halo” of the first impression. We will see in <a href="part0035.xhtml">chapter 24</a>
 that the halo effect is a serious problem in hiring decisions.)</div>
<div class="s4P">Here is another example. In the United States, public officials have required chain restaurants to include calorie labels to ensure that consumers see the calories associated with, for example, cheeseburgers, hamburgers, and salads. After seeing those labels, do consumers change their choices? The evidence is disputed and mixed. But in a revealing study, consumers were found to be more likely to be affected by calorie labels if they were placed to the left of the food item rather than the right. When calories are on the left, consumers receive that information first and evidently think “a lot of calories!” or “not so many calories!” before they see the item. Their initial positive or negative reaction greatly affects their choices. By contrast, when people see the food item first, they apparently think “delicious!” or “not so great!” before they see the calorie label. Here again, their initial reaction greatly affects their choices. This hypothesis is supported by the authors’ finding that for Hebrew speakers, who read right to left, the calorie label has a significantly larger impact if it is on the right rather than the left.</div>
<div class="s4P">In general, we jump to conclusions, then stick to them. We think we base our opinions on evidence, but the evidence we <span id="page_162"></span>
consider and our interpretation of it are likely to be distorted, at least to some extent, to fit our initial snap judgment. As a result, we maintain the coherence of the overall story that has emerged in our mind. This process is fine, of course, if the conclusions are correct. When the initial evaluation is erroneous, however, the tendency to stick to it in the face of contradictory evidence is likely to amplify errors. And this effect is difficult to control, because information that we have heard or seen is impossible to ignore and often difficult to forget. In court, judges sometimes instruct jurors to disregard an inadmissible piece of evidence they have heard, but this is not a realistic instruction (although it may be helpful in jury deliberation, where arguments explicitly based on this evidence can be rejected).</div>
<div class="s7D">Psychological Biases Cause Noise</div>
<div class="s4M">We have briefly presented three types of biases that operate in different ways: substitution biases, which lead to a misweighting of the evidence; conclusion biases, which lead us either to bypass the evidence or to consider it in a distorted way; and excessive coherence, which magnifies the effect of initial impressions and reduces the impact of contradictory information. All three types of biases can, of course, produce statistical bias. They can also produce noise.</div>
<div class="s4P">Let’s start with substitution. Most people judge the probability that Bill is an accountant by the similarity of his profile to a stereotype: the result, in this experiment, is a shared bias. If every respondent makes the same mistake, there is no noise. But substitution does not always produce such unanimity. When the question “Is there climate change?” is replaced with “Do I trust the people who say it is real?,” it is easy to see that the answer will vary from one person to the next, depending on that person’s social circles, preferred sources of information, political affiliation, and so on. The same psychological bias creates variable judgments and between-person noise.</div>
<div class="s4P">Substitution can also be a source of occasion noise. If a question on life satisfaction is answered by consulting one’s immediate mood, the answer will inevitably vary for the same person from one moment to the next. A happy morning can be <span id="page_163"></span>
followed by a distressing afternoon, and changing moods over time can lead to very different reports of life satisfaction depending on when the interviewer happens to call. In <a href="part0015.xhtml">chapter 7</a>
, we reviewed examples of occasion noise that can be traced to psychological biases.</div>
<div class="s4P">Prejudgments also produce both bias and noise. Return to an example we mentioned in the introduction: the shocking disparities in the percentage of asylum seekers that judges admit. When one judge admits 5% of applicants and another in the same courthouse admits 88%, we can be quite certain that they are biased in different directions. From a broader perspective, individual differences in biases can cause massive system noise. Of course, the system can also be biased to the extent that most or all judges are biased similarly.</div>
<div class="s4P">Finally, excessive coherence can produce either bias or noise, depending on whether the sequence of information and the meaning assigned to it are identical for all (or most) judges. Consider, for instance, a physically attractive candidate whose good looks create an early positive impression in most recruiters. If physical appearance is irrelevant to the position for which the candidate is considered, this positive halo will result in a shared error: a bias.</div>
<div class="s4P">On the other hand, many complex decisions require compiling information that arrives in an essentially random order. Consider the claims adjusters of <a href="part0009.xhtml">chapter 2</a>
. The order in which data about a claim becomes available varies haphazardly from one adjuster to the next and from one case to the next, causing random variation in initial impressions. Excessive coherence means that these random variations will produce random distortions in the final judgments. The effect will be system noise.</div>
<div class="s7X-1"><img src="rsrc31A.jpg" alt="" class="s7X-0" />
</div>
<div class="s7Z">In short, psychological biases, as a mechanism, are universal, and they often produce shared errors. But when there are large individual differences in biases (different prejudgments) or when the effect of biases depends on context (different triggers), there will be noise.</div>
<div class="s4P">Both bias and noise create error, which suggests that <span id="page_164"></span>
anything that reduces psychological biases will improve judgment. We will return to the topic of debiasing, or removing bias, in <a href="part0028.xhtml">part 5</a>
. But for now, we continue our exploration of the process of judgment.</div>
<div class="s84">Speaking of Heuristics, Biases, and Noise</div>
<div class="s86">
<span class="class-2">“We know we have psychological biases, but we should resist the urge to blame every error on unspecified ‘biases.’”</span>
</div>
<div class="s88">
<span class="class-2">“When we substitute an easier question for the one we should be answering, errors are bound to occur. For instance, we will ignore the base rate when we judge probability by similarity.”</span>
</div>
<div class="s88">
<span class="class-2">“Prejudgments and other conclusion biases lead people to distort evidence in favor of their initial position.”</span>
</div>
<div class="s88">
<span class="class-2">“We form impressions quickly and hold on to them even when contradictory information comes in. This tendency is called excessive coherence.”</span>
</div>
<div class="s8A">
<span class="class-2">“Psychological biases cause statistical bias if many people share the same biases. In many cases, however, people differ in their biases. In those cases, psychological biases create system noise.”</span>
</div>
</body>
</html>
