<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>part0030</title>
<link rel="stylesheet" type="text/css" href="stylesheet.css" />
</head>
<body>
<div id="page_220" class="s6B">
<a href="part0003.xhtml#a2XH">CHAPTER 19</a>
</div>
<div class="s6T">
<a href="part0003.xhtml#a2XH">Debiasing and Decision Hygiene</a>
</div>
<div class="s4M">
<span class="s2WY">M</span>
any researchers and organizations have pursued the goal of debiasing judgments. This chapter examines their central findings. We will distinguish between different types of debiasing interventions and discuss one such intervention that deserves further investigation. We will then turn to the reduction of noise and introduce the idea of decision hygiene.</div>
<div class="s7D">Ex Post and Ex Ante Debiasing</div>
<div class="s4M">A good way to characterize the two main approaches to debiasing is to return to the measurement analogy. Suppose that you know that your bathroom scale adds, on average, half a pound to your weight. Your scale is biased. But this does not make it useless. You can address its bias in one of two possible ways. You can correct every reading from your unkindly scale by subtracting half a pound. To be sure, that might get a bit tiresome (and you might forget to do it). An alternative might be to adjust the dial and improve the instrument’s accuracy, once and for all.</div>
<div class="s4P">These two approaches to debiasing measurements have direct analogues in interventions to debias judgments. They work either ex post, by correcting judgments after they have been made, or ex ante, by intervening before a judgment or decision.</div>
<div class="s4P">Ex post, or corrective, debiasing is often carried out intuitively. Suppose that you are supervising a team in charge of a project and that the team estimates that it can complete its project in three months. You might want to add a buffer to the members’ judgment and plan for four months, or more, thus correcting a bias <span id="page_221"></span>
(the planning fallacy) you assume is present.</div>
<div class="s4P">This kind of bias correction is sometimes undertaken more systematically. In the United Kingdom, HM Treasury has published <span class="s2WT-0">The Green Book,</span>
 a guide on how to evaluate programs and projects. The book urges planners to address optimistic biases by applying percentage adjustments to estimates of the cost and duration of a project. These adjustments should ideally be based on an organization’s historic levels of optimism bias. If no such historical data is available, <span class="s2WT-0">The Green Book</span>
 recommends applying generic adjustment percentages for each type of project.</div>
<div class="s4P">Ex ante or preventive debiasing interventions fall in turn into two broad categories. Some of the most promising are designed to modify the environment in which the judgment or decision takes place. Such modifications, or <span class="s2WT-0">nudges,</span>
 as they are known, aim to reduce the effect of biases or even to enlist biases to produce a better decision. A simple example is automatic enrollment in pension plans. Designed to overcome inertia, procrastination, and optimistic bias, automatic enrollment ensures that employees will be saving for retirement unless they deliberately opt out. Automatic enrollment has proved to be extremely effective in increasing participation rates. The program is sometimes accompanied by Save More Tomorrow plans, by which employees can agree to earmark a certain percentage of their future wage increases for savings. Automatic enrollment can be used in many places—for example, automatic enrollment in green energy, in free school meal plans for poor children, or in various other benefits programs.</div>
<div class="s4P">Other nudges work on different aspects of choice architecture. They might make the right decision the easy decision—for example, by reducing administrative burdens for getting access to care for mental health problems. Or they might make certain characteristics of a product or an activity salient—for example, by making once-hidden fees explicit and clear. Grocery stores and websites can easily be designed to nudge people in a way that overcomes their biases. If healthy foods are put in prominent places, more people are likely to buy them.</div>
<div class="s4P">A different type of ex ante debiasing involves training decision makers to recognize their biases and to overcome them. Some of these interventions have been called <span class="s2WT-0">boosting;</span>
 they aim to improve people’s capacities—for example, by teaching them <span id="page_222"></span>
statistical literacy.</div>
<div class="s4P">Educating people to overcome their biases is an honorable enterprise, but it is more challenging than it seems. Of course, education is useful. For instance, people who have taken years of advanced statistics classes are less likely to make errors in statistical reasoning. But teaching people to avoid biases is hard. Decades of research have shown that professionals who have learned to avoid biases in their area of expertise often struggle to apply what they have learned to different fields. Weather forecasters, for instance, have learned to avoid overconfidence in their forecasts. When they announce a 70% chance of rain, it rains, by and large, 70% of the time. Yet they can be just as overconfident as other people when asked general-knowledge questions. The challenge of learning to overcome a bias is to recognize that a new problem is similar to one we have seen elsewhere and that a bias that we have seen in one place is likely to materialize in other places.</div>
<div class="s4P">Researchers and educators have had some success using nontraditional teaching methods to facilitate this recognition. In one study, Carey Morewedge of Boston University and his colleagues used instructional videos and “serious games.” Participants learned to recognize errors caused by confirmation bias, anchoring, and other psychological biases. After each game, they received feedback on the errors they had made and learned how to avoid making them again. The games (and, to a lesser extent, the videos) reduced the number of errors that participants made on a test immediately afterward and again eight weeks later, when they were asked similar questions. In a separate study, Anne-Laure Sellier and her colleagues found that MBA students who had played an instructional video game in which they learned to overcome confirmation bias applied this learning when solving a business case in another class. They did so even though they were not told that there was any connection between the two exercises.</div>
<div class="s7D">A Limitation of Debiasing</div>
<div class="s4M">Whether they correct biases ex post or prevent their effects through nudging or boosting, most debiasing approaches have one thing in common: they target a specific bias, which they assume is present. <span id="page_223"></span>
This often-reasonable assumption is sometimes wrong.</div>
<div class="s4P">Consider again the example of project planning. You can reasonably assume that overconfidence affects project teams in general, but you cannot be sure that it is the only bias (or even the main one) affecting a particular project team. Maybe the team leader has had a bad experience with a similar project and so has learned to be especially conservative when making estimates. The team thus exhibits the opposite error from the one you thought you should correct. Or perhaps the team developed its forecast by analogy with another similar project and was anchored on the time it took to complete that project. Or maybe the project team, anticipating that you would add a buffer to its estimate, has preempted your adjustment by making its recommendation even more bullish than its true belief.</div>
<div class="s4P">Or consider an investment decision. Overconfidence about the investment’s prospects may certainly be at work, but another powerful bias, loss aversion, has the opposite effect, making decision makers loath to risk losing their initial outlay. Or consider a company allocating resources across multiple projects. Decision makers may be both bullish about the effect of new initiatives (overconfidence again) and too timid in diverting resources from existing units (a problem caused by <span class="s2WT-0">status quo bias,</span>
 which, as the name indicates, is our preference for leaving things as they are).</div>
<div class="s4P">As these examples illustrate, it is difficult to know exactly which psychological biases are affecting a judgment. In any situation of some complexity, multiple psychological biases may be at work, conspiring to add error in the same direction or offsetting one another, with unpredictable consequences.</div>
<div class="s4P">The upshot is that ex post or ex ante debiasing—which, respectively, correct or prevent specific psychological biases—are useful in some situations. These approaches work where the general direction of error is known and manifests itself as a clear statistical bias. Types of decisions that are expected to be strongly biased are likely to benefit from debiasing interventions. For instance, the planning fallacy is a sufficiently robust finding to warrant debiasing interventions against overconfident planning.</div>
<div class="s4P">The problem is that in many situations, the likely direction of error is not known in advance. Such situations include all those in which the effect of psychological biases is variable among judges and <span id="page_224"></span>
essentially unpredictable—resulting in system noise. To reduce error under circumstances like these, we need to cast a broader net to try to detect more than one psychological bias at a time.</div>
<div class="s7D">The Decision Observer</div>
<div class="s4M">We suggest undertaking this search for biases neither before nor after the decision is made, but in real time. Of course, people are rarely aware of their own biases when they are being misled by them. This lack of awareness is itself a known bias, the <span class="s2WT-0">bias blind spot.</span>
 People often recognize biases more easily in others than they do in themselves. We suggest that observers can be trained to spot, in real time, the diagnostic signs that one or several familiar biases are affecting someone else’s decisions or recommendations.</div>
<div class="s4P">To illustrate how the process might work, imagine a group that attempts to make a complex and consequential judgment. The judgment could be of any type: a government deciding on possible responses to a pandemic or other crisis, a case conference in which physicians are exploring the best treatment for a patient with complex symptoms, a corporate board deciding on a major strategic move. Now imagine a <span class="s2WT-0">decision observer,</span>
 someone who watches this group and uses a checklist to diagnose whether any biases may be pushing the group away from the best possible judgment.</div>
<div class="s4P">A decision observer is not an easy role to play, and no doubt, in some organizations it is not realistic. Detecting biases is useless if the ultimate decision makers are not committed to fighting them. Indeed, the decision makers must be the ones who initiate the process of decision observation and who support the role of the decision observer. We certainly do not recommend that you make yourself a self-appointed decision observer. You will neither win friends nor influence people.</div>
<div class="s4P">Informal experiments suggest, however, that real progress can be made with this approach. At least, the approach is helpful under the right conditions, especially when the leaders of an organization or team are truly committed to the effort, and when the decision observers are well chosen—and not susceptible to serious biases of their own.</div>
<div class="s4P">Decision observers in these cases fall in three categories. In <span id="page_225"></span>
some organizations, the role can be played by a supervisor. Instead of monitoring only the substance of the proposals that are submitted by a project team, the supervisor might also pay close attention to the <span class="s2WT-0">process</span>
 by which they are developed and to the team’s dynamics. This makes the observer alert to biases that may have affected the proposal’s development. Other organizations might assign a member of each working team to be the team’s “bias buster”; this guardian of the decision process reminds teammates in real time of the biases that may mislead them. The downside of this approach is that the decision observer is placed in the position of a devil’s advocate inside the team and may quickly run out of political capital. Finally, other organizations might rely on an outside facilitator, who has the advantage of a neutral perspective (and the attending disadvantages in terms of inside knowledge and costs).</div>
<div class="s4P">To be effective, decision observers need some training and tools. One such tool is a checklist of the biases they are attempting to detect. The case for relying on a checklist is clear: checklists have a long history of improving decisions in high-stakes contexts and are particularly well suited to preventing the repetition of past errors.</div>
<div class="s4P">Here is an example. In the United States, federal agencies must compile a formal regulatory impact analysis before they issue expensive regulations designed to clean the air or water, reduce deaths in the workplace, increase food safety, respond to public health crises, reduce greenhouse gas emissions, or increase homeland security. A dense, technical document with an unlovely name (OMB Circular A-4) and spanning nearly fifty pages sets out the requirements of the analysis. The requirements are clearly designed to counteract bias. Agencies must explain why the regulation is needed, consider both more and less stringent alternatives, consider both costs and benefits, present the information in an unbiased manner, and discount the future appropriately. But in many agencies, government officials have not complied with the requirements of that dense, technical document. (They might not even have read it.) In response, federal officials produced a simple checklist, consisting of just one and one-half pages, to reduce the risk that agencies will ignore, or fail to attend to, any of the major requirements.</div>
<div class="s4P">To illustrate what a bias checklist might look like, we have included one as appendix B. This generic checklist is merely an <span id="page_226"></span>
example; any decision observer will certainly want to develop one that is customized to the needs of the organization, both to enhance its relevance and facilitate its adoption. Importantly, a checklist is not an exhaustive list of all the biases that can affect a decision; it aims to focus on the most frequent and most consequential ones.</div>
<div class="s4P">Decision observation with appropriate bias checklists can help limit the effect of biases. Although we have seen some encouraging results in informal, small-scale efforts, we are not aware of any systematic exploration of the effects of this approach or of the pros and cons of the various possible ways to deploy it. We hope to inspire more experimentation, both by practitioners and by researchers, of the practice of real-time debiasing by decision observers.</div>
<div class="s7D">Noise Reduction: Decision Hygiene</div>
<div class="s4M">Bias is error we can often see and even explain. It is directional: that is why a nudge can limit the detrimental effects of a bias, or why an effort to boost judgment can combat specific biases. It is also often visible: that is why an observer can hope to diagnose biases in real time as a decision is being made.</div>
<div class="s4P">Noise, on the other hand, is unpredictable error that we cannot easily see or explain. That is why we so often neglect it—even when it causes grave damage. For this reason, strategies for noise reduction are to debiasing what preventive hygiene measures are to medical treatment: the goal is to prevent an unspecified range of potential errors before they occur.</div>
<div class="s4P">We call this approach to noise reduction <span class="s2WT-0">decision hygiene.</span>
 When you wash your hands, you may not know precisely which germ you are avoiding—you just know that handwashing is good prevention for a variety of germs (especially but not only during a pandemic). Similarly, following the principles of decision hygiene means that you adopt techniques that reduce noise without ever knowing which underlying errors you are helping to avoid.</div>
<div class="s4P">The analogy with handwashing is intentional. Hygiene measures can be tedious. Their benefits are not directly visible; you might never know what problem they prevented from occurring. Conversely, when problems do arise, they may not be traceable to a <span id="page_227"></span>
specific breakdown in hygiene observance. For these reasons, handwashing compliance is difficult to enforce, even among health-care professionals, who are well aware of its importance.</div>
<div class="s4P">Just like handwashing and other forms of prevention, decision hygiene is invaluable but thankless. Correcting a well-identified bias may at least give you a tangible sense of achieving something. But the procedures that reduce noise will not. They will, statistically, prevent many errors. Yet you will never know <span class="s2WT-0">which</span>
 errors. Noise is an invisible enemy, and preventing the assault of an invisible enemy can yield only an invisible victory.</div>
<div class="s4P">Given how much damage noise can cause, that invisible victory is nonetheless worth the battle. The following chapters introduce several decision hygiene strategies used in multiple domains, including forensic science, forecasting, medicine, and human resources. In <a href="part0036.xhtml">chapter 25</a>
, we will review these strategies and show how they can be combined in an integrated approach to noise reduction.</div>
<div class="s84">Speaking of Debiasing and Decision Hygiene</div>
<div class="s86">
<span class="class-2">“Do you know what specific bias you’re fighting and in what direction it affects the outcome? If not, there are probably several biases at work, and it is hard to predict which one will dominate.”</span>
</div>
<div class="s88">
<span class="class-2">“Before we start discussing this decision, let’s designate a decision observer.”</span>
</div>
<div class="s8A">
<span class="class-2">“We have kept good decision hygiene in this decision process; chances are the decision is as good as it can be.”</span>
</div>
</body>
</html>
