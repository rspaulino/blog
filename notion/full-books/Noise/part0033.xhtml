<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>part0033</title>
<link rel="stylesheet" type="text/css" href="stylesheet.css" />
</head>
<body>
<div id="page_254" class="s6B">
<a href="part0003.xhtml#a2Z3">CHAPTER 22</a>
</div>
<div class="s6T">
<a href="part0003.xhtml#a2Z3">Guidelines in Medicine</a>
</div>
<div class="s4M">
<span class="s2WY">S</span>
ome years ago, a good friend of ours (let’s call him Paul) was diagnosed with high blood pressure by his primary care doctor (we will call him Dr. Jones). The doctor advised Paul to try medication. Dr. Jones prescribed a diuretic, but it had no effect; Paul’s blood pressure remained high. A few weeks later, Dr. Jones responded with a second medication, a calcium channel blocker. Its effect was also modest.</div>
<div class="s4P">These results baffled Dr. Jones. After three months of weekly office visits, Paul’s high blood pressure readings had dropped slightly, but they were still too high. It wasn’t clear what the next steps would be. Paul was anxious and Dr. Jones was troubled, not least because Paul was a relatively young man in good health. Dr. Jones contemplated trying a third medication.</div>
<div class="s4P">At that point, Paul happened to move to a new city, where he consulted a new primary care doctor (we will call him Dr. Smith). Paul told Dr. Smith the story of his continuing struggles with high blood pressure. Dr. Smith immediately responded, “Buy a home blood pressure kit, and see what the readings are. I don’t think you have high blood pressure at all. You probably just have white coat syndrome—your blood pressure goes up in doctors’ offices!”</div>
<div class="s4P">Paul did as he was told, and sure enough, his blood pressure was normal at home. It has been normal ever since (and a month after Dr. Smith told him about white coat syndrome, it became normal in doctors’ offices as well).</div>
<div class="s4P">A central task of doctors is to make diagnoses—to decide whether a patient has some kind of illness and, if so, to identify it. Diagnosis often requires some kind of judgment. For many conditions, the diagnosis is routine and largely mechanical, and <span id="page_255"></span>
rules and procedures are in place to minimize noise. It’s usually easy for a doctor to determine whether someone has a dislocated shoulder or a broken toe. Something similar can be said about problems that are more technical. Quantifying tendon degeneration produces little noise. When pathologists evaluate core needle biopsies of breast lesions, their evaluations are relatively straightforward, with little noise.</div>
<div class="s4P">Importantly, some diagnoses do not involve judgment at all. Health care often progresses by removing the element of judgment—by shifting from judgment to calculation. For strep throat, a doctor will begin with a rapid antigen test on a swab sample from a patient’s throat. In a short period, the test can detect strep bacteria. (Without the rapid antigen result, and to some extent even with it, there is noise in diagnosis of strep throat.) If you have a fasting blood sugar level of 126 milligrams per deciliter or higher or an HbA1c (an average measure of blood sugar over the prior three months) of at least 6.5, you are considered to have diabetes. During the early stages of the COVID-19 pandemic, some doctors initially made diagnoses as a result of judgments reached after considering symptoms; as the pandemic progressed, testing became much more common, and the tests made judgment unnecessary.</div>
<div class="s4P">Many people know that when doctors do exercise judgment, they can be noisy, and they might err; a standard practice is to advise patients to get a second opinion. In some hospitals, a second opinion is even mandatory. Whenever the second opinion diverges from the first, we have noise—though of course it may not be clear which doctor has it right. Some patients (including Paul) have been astonished to see how much the second opinion diverges from the first. But the surprise is not the existence of noise in the medical profession. It is its sheer magnitude.</div>
<div class="s4P">Our goals in this chapter are to elaborate that claim and to describe some of the approaches to noise reduction used by the medical profession. We will focus on one decision hygiene strategy: the development of diagnostic guidelines. We are keenly aware that an entire book could easily be written about noise in medicine and the various steps that doctors, nurses, and hospitals have been taking by way of remedy. Notably, noise in medicine is hardly limited to noise in diagnostic judgments, which is our focus here. Treatments can also be noisy, and an extensive literature addresses <span id="page_256"></span>
this topic as well. If a patient has a heart problem, doctors’ judgments about the best treatment are shockingly variable, whether the question involves the right medication, the right kind of surgery, or whether to get surgery at all. The Dartmouth Atlas Project has dedicated itself, for more than twenty years, to documenting “glaring variations in how medical resources are distributed and used in the United States.” Similar conclusions hold in numerous nations. For our purposes, however, a brief exploration of noise in diagnostic judgments will be sufficient.</div>
<div class="s7D">A Tour of the Horizon</div>
<div class="s4M">There is an immense literature on noise in medicine. While much of the literature is empirical, testing for the presence of noise, much of it is also prescriptive. Those involved in health care are continuing to search for noise-reduction strategies, which take many forms and are a gold mine of ideas worth considering in many fields.</div>
<div class="s4P">When there is noise, one physician may be clearly right and the other may be clearly wrong (and may suffer from some kind of bias). As might be expected, skill matters a lot. A study of pneumonia diagnoses by radiologists, for instance, found significant noise. Much of it came from differences in skill. More specifically, “variation in skill can explain 44% of the variation in diagnostic decisions,” suggesting that “policies that improve skill perform better than uniform decision guidelines.” Here as elsewhere, training and selection are evidently crucial to the reduction of error, and to the elimination of both noise and bias.</div>
<div class="s4P">In some specialties, such as radiology and pathology, doctors are well aware of the presence of noise. Radiologists, for example, call diagnostic variation their “Achilles’ heel.” It is not clear whether noise in the fields of radiology and pathology receives particular attention because there is truly more noise in these fields than in others or simply because noise is more easily documented there. We suspect that ease of documentation may be more important. Clean, simple tests of noise (and sometimes error) are easier to conduct in radiology. For example, you can return to scans or slides to reevaluate a previous assessment.</div>
<div class="s4P">In medicine, between-person noise, or <span class="s2WT-0">interrater reliability,</span>
 is usually measured by the <span class="s2WT-0">kappa statistic.</span>
<span id="page_257"></span>
 The higher the kappa, the less noise. A kappa value of 1 reflects perfect agreement; a value of 0 reflects exactly as much agreement as you would expect between monkeys throwing darts onto a list of possible diagnoses. In some domains of medical diagnosis, reliability as measured by this coefficient has been found to be “slight” or “poor,” which means that noise is very high. It is often found to be “fair,” which is of course better but which also indicates significant noise. On the important question of which drug-drug interactions are clinically significant, generalist physicians, reviewing one hundred randomly selected drug-drug interactions, showed “poor agreement.” To outsiders and to many doctors, diagnosis of the various stages of kidney disease might seem relatively straightforward. But nephrologists show only “slight to moderate agreement” in their judgments about the meaning of standard tests used in the evaluation of patients with kidney disease.</div>
<div class="s4P">On the question of whether a breast lesion was cancerous, one study found only “fair” agreement among pathologists. In diagnosing breast proliferative lesions, agreement was again only “fair.” Agreement was also “fair” when physicians assessed MRI scans for the degree of spinal stenosis. It is worth pausing over these findings. We have said that in some domains, the level of noise in medicine is very low. But in some areas that are fairly technical, doctors are far from noise-free. Whether a patient will be diagnosed with a serious disease, such as cancer, might depend on a kind of lottery, determined by the particular doctor that she will see.</div>
<div class="s4P">Consider just a few other findings from the literature, drawn from areas in which the volume of noise seems especially noteworthy. We describe these findings not to give authoritative statements about the current state of medical practice, which continues to evolve and improve (in some cases rapidly), but to convey a general sense of the pervasiveness of noise, both in the relatively recent past and in the present.</div>
<div class="s1M9">1. Heart disease is the leading cause of death in both men and women in the United States. Coronary angiograms, a primary method used to test for heart disease, assess the degree of blockage in the heart’s arteries in both acute and nonacute settings. In <span id="page_258"></span>
nonacute settings, when a patient presents with recurrent chest pain, treatment—such as stent placement—is often pursued if more than 70% of one or more arteries is found to be blocked. However, a degree of variability in interpreting angiograms has been documented, potentially leading to unnecessary procedures. An early study found that 31% of the time, physicians evaluating angiograms disagreed on whether a major vessel was more than 70% blocked. Despite widespread awareness by cardiologists of potential variability in reading angiograms, and despite continuing efforts and corrective steps, the problem has yet to be solved.</div>
<div class="s1MB">2. Endometriosis is a disorder in which endometrial tissue, normally lining the inside of the uterus, grows outside the uterus. The disorder can be painful and lead to fertility problems. It is often diagnosed through laparoscopy, in which a small camera is surgically inserted into the body. Digital videos of laparoscopies in three patients, two of whom had endometriosis of varying degrees of severity and one of whom did not, were shown to 108 gynecological surgeons. The surgeons were asked to judge the number and location of endometriotic lesions. They disagreed dramatically, with weak correlations on both number and location.</div>
<div class="s1MB">3. Tuberculosis (TB) is one of the most widespread and deadly diseases worldwide—in 2016 alone, it infected more than 10 million people and killed almost 2 million. A widely used method for detecting TB is a chest X-ray, which allows examination of the lungs for the empty space caused by the TB bacteria. Variability in diagnosis of TB has been well documented for almost seventy-five years. Despite improvements over the decades, studies have continued to find significant variability in diagnosis of TB, with “moderate” or just “fair” interrater agreement. There is also variability in TB diagnoses between radiologists in different countries.</div>
<div class="s1MB">4. When pathologists analyzed skin lesions for the presence of melanoma—the most dangerous form of skin cancer—there was only “moderate” agreement. The eight pathologists reviewing each case <span id="page_259"></span>
were unanimous or showed only one disagreement just 62% of the time. Another study at an oncology center found that the diagnostic accuracy of melanomas was only 64%, meaning that doctors misdiagnosed melanomas in one of every three lesions. A third study found that dermatologists at New York University failed to diagnose melanoma from skin biopsies 36% of the time. The authors of the study conclude that “the clinical failure to diagnose melanoma correctly has grievous implications for survival of patients with that potentially fatal disease.”</div>
<div class="s1MD">5. There is variability in radiologists’ judgments with respect to breast cancer from screening mammograms. A large study found that the range of false negatives among different radiologists varied from 0% (the radiologist was correct every time) to greater than 50% (the radiologist incorrectly identified the mammogram as normal more than half of the time). Similarly, false-positive rates ranged from less than 1% to 64% (meaning that nearly two-thirds of the time, the radiologist said the mammogram showed cancer when cancer was not present). False negatives and false positives, from different radiologists, ensure that there is noise.</div>
<div class="s4P">These cases of interpersonal noise dominate the existing research, but there are also findings of occasion noise. Radiologists sometimes offer a different view when assessing the same image again and thus disagree with themselves (albeit less often than they disagree with others). When assessing the degree of blockage in angiograms, twenty-two physicians disagreed with themselves between 63 and 92% of the time. In areas that involve vague criteria and complex judgments, intrarater reliability, as it is called, can be poor.</div>
<div class="s4P">These studies offer no clear explanation of this occasion noise. But another study, not involving diagnosis, identifies a simple source of occasion noise in medicine—a finding worth bearing in mind for both patients and doctors. In short, doctors are significantly more likely to order cancer screenings early in the morning than late in the afternoon. In a large sample, the order rates of breast and colon screening tests were highest at 8 a.m., at 63.7%. They decreased throughout the morning to 48.7% at 11 a.m. They <span id="page_260"></span>
increased to 56.2% at noon—and then decreased to 47.8% at 5 p.m. It follows that patients with appointment times later in the day were less likely to receive guideline-recommended cancer screening.</div>
<div class="s4P">How can we explain such findings? A possible answer is that physicians almost inevitably run behind in clinic after seeing patients with complex medical problems that require more than the usual twenty-minute slot. We already mentioned the role of stress and fatigue as triggers of occasion noise (see <a href="part0015.xhtml">chapter 7</a>
), and these elements seem to be at work here. To keep up with their schedules, some doctors skip discussions about preventive health measures. Another illustration of the role of fatigue among clinicians is the lower rate of appropriate handwashing during the end of hospital shifts. (Handwashing turns out to be noisy, too.)</div>
<div class="s7D">Less Noisy Doctors: The Value of Guidelines</div>
<div class="s4M">It would be a major contribution not only to medicine but also to human knowledge to provide a comprehensive account of the existence and magnitude of noise in the context of different medical problems. We are unaware of any such account; we hope that it will be produced in the fullness of time. But even now, existing findings provide some clues.</div>
<div class="s4P">At one extreme, diagnosis for some problems and illnesses is essentially mechanical and allows no room for judgment. In other cases, the diagnosis is not mechanical but straightforward; anyone with medical training is highly likely to reach the same conclusion. In still other cases, a degree of specialization—among, say, lung cancer specialists—will be sufficient to ensure that noise exists but is minimal. At the other extreme, some cases present a great deal of room for judgment, and the relevant criteria for diagnosis are so open-ended that noise will be substantial and difficult to reduce. As we will see, this is the case in much of psychiatry.</div>
<div class="s4P">What might work to reduce noise in medicine? As we mentioned, training can increase skill, and skill certainly helps. So does the aggregation of multiple expert judgments (second opinions and so forth). Algorithms offer an especially promising avenue, and doctors are now using deep-learning algorithms and artificial intelligence to reduce noise. For example, such algorithms have <span id="page_261"></span>
been used to detect lymph node metastases in women with breast cancer. The best of these have been found to be superior to the best pathologist, and, of course, algorithms are not noisy. Deep-learning algorithms have also been used, with considerable success, for the detection of eye problems associated with diabetes. And AI now performs at least as well as radiologists do in detecting cancer from mammograms; further advances in AI will probably demonstrate its superiority.</div>
<div class="s4P">The medical profession is likely to rely on algorithms more and more in the future; they promise to reduce both bias and noise and to save lives and money in the process. But our emphasis here will be on human-judgment guidelines, because the domain of medicine helpfully illustrates how they produce good or even excellent results in some applications and more mixed results in others.</div>
<div class="s4P">Perhaps the most famous example of a guideline for diagnosis is the Apgar score, developed in 1952 by the obstetric anesthesiologist Virginia Apgar. Assessing whether a newborn baby is in distress used to be a matter of clinical judgment for physicians and midwives. Apgar’s score gave them a standard guideline instead. The evaluator measures the baby’s color, heart rate, reflexes, muscle tone, and respiratory effort, sometimes summarized as a “backronym” for Apgar’s name: <span class="s2WT-0">appearance</span>
 (skin color), <span class="s2WT-0">pulse</span>
 (heart rate), <span class="s2WT-0">grimace</span>
 (reflexes), <span class="s2WT-0">activity</span>
 (muscle tone), and <span class="s2WT-0">respiration</span>
 (breathing rate and effort). In the Apgar test, each of these five measures is given a score of 0, 1, or 2. The highest possible total score is 10, which is rare. A score of 7 or above is considered indicative of good health (<a href="part0033.xhtml#a2Z9">table 3</a>
).</div>
<div class="sRD">
<div id="a2Z9">
<span class="s2WV-0">Table 3:</span>
 <span class="s2WT-0">Apgar Scoring Guidelines</span>
</div>
</div>
<div class="sRF">
<span class="s2WU">Category</span>
<span class="s2WV-0">:</span>
 <span class="s2WV-0">Appearance (skin color)</span>
</div>
<div class="sY">
<span class="s2WU">Number of points assigned</span>
<span class="s2WV-0">:</span>
 0: Entire body is blue or pale</div>
<div class="s1PC">
<span class="class-1">1: Good color in body but blue hands or feet</span>
</div>
<div class="s1PE">
<span class="class-1">2: Completely pink or normal color</span>
</div>
<div class="sRF">
<span class="s2WU">Category</span>
<span class="s2WV-0">:</span>
 <span class="s2WU">Category</span>
<span class="s2WV-0">:</span>
 <span class="s2WV-0">Pulse (heart rate)</span>
</div>
<div class="sY">
<span class="s2WU">Number of points assigned</span>
<span class="s2WV-0">:</span>
 0: No heart rate</div>
<div class="s1PC">
<span class="class-1">1: &lt;100 beats per minute</span>
</div>
<div id="page_262" class="s1PE">
<span class="class-1">2: &gt;100 beats per minute</span>
</div>
<div class="sRF">
<span class="s2WU">Category</span>
<span class="s2WV-0">:</span>
 <span class="s2WV-0">Grimace (reflexes)</span>
</div>
<div class="sY">
<span class="s2WU">Number of points assigned</span>
<span class="s2WV-0">:</span>
 0: No response to airways being stimulated</div>
<div class="s1PC">
<span class="class-1">1: Grimace during stimulation</span>
</div>
<div class="s1PE">
<span class="class-1">2: Grimace and cough or sneeze during stimulation</span>
</div>
<div class="sRF">
<span class="s2WU">Category</span>
<span class="s2WV-0">:</span>
 <span class="s2WV-0">Activity (muscle tone)</span>
</div>
<div class="sY">
<span class="s2WU">Number of points assigned</span>
<span class="s2WV-0">:</span>
 0: Limp</div>
<div class="s1PC">
<span class="class-1">1: Some flexing (bending) of arms and legs</span>
</div>
<div class="s1PE">
<span class="class-1">2: Active motion</span>
</div>
<div class="sRF">
<span class="s2WU">Category</span>
<span class="s2WV-0">:</span>
 <span class="s2WV-0">Respiration (breathing rate and effort)</span>
</div>
<div class="sY">
<span class="s2WU">Number of points assigned</span>
<span class="s2WV-0">:</span>
 0: Not breathing</div>
<div class="s1PC">
<span class="class-1">1: Weak cry (whimpering, grunting)</span>
</div>
<div class="s1PE">
<span class="class-1">2: Good, strong cry</span>
</div>
<div class="s1R0">Note that heart rate is the only strictly numerical component of the score and that all the other items involve an element of judgment. But because the judgment is decomposed into individual elements, each of which is straightforward to assess, practitioners with even a modest degree of training are unlikely to disagree a great deal—and hence Apgar scoring produces little noise.</div>
<div class="s4P">The Apgar score exemplifies how guidelines work and why they reduce noise. Unlike rules or algorithms, guidelines do not eliminate the need for judgment: the decision is not a straightforward computation. Disagreement remains possible on each of the components and hence on the final conclusion. Yet guidelines succeed in reducing noise because they decompose a complex decision into a number of easier subjudgments on predefined dimensions.</div>
<div class="s4P">The benefits of this approach are clear when we view the problem in terms of the simple prediction models discussed in <a href="part0018.xhtml">chapter 9</a>
. A clinician making a judgment about a newborn’s health is working from several predictive cues. Occasion noise might be at work: on one day but not another, or in one mood but not another, a clinician could pay attention to relatively unimportant predictors or <span id="page_263"></span>
ignore important ones. The Apgar score focuses the health professional on the five that are empirically known to matter. Then, the score provides a clear description of how to evaluate each cue, which greatly simplifies each cue-level judgment and hence reduces its noise. Finally, the Apgar score specifies how to weight the predictors mechanically to produce the overall judgment required, whereas human clinicians would otherwise differ on the weights they assign to the cues. A focus on the relevant predictors, simplification of the predictive model, and mechanical aggregation—all of these reduce noise.</div>
<div class="s4P">Analogous approaches have been used in many medical domains. One example is the Centor score to guide diagnosis of strep throat. A patient is given one point for each of the following symptoms or signs (whose terms, like the Apgar score, constitute a backronym for the last name of Robert Centor, who with his colleagues first summarized this guideline): absence of a <span class="s2WT-0">cough</span>
, presence of <span class="s2WT-0">exudates</span>
 (white patches on the back of throat), tender or swollen lymph <span class="s2WT-0">nodes</span>
 in the neck, and a <span class="s2WT-0">temperature</span>
 greater than 100.4 degrees. Depending on the number of points a patient is assigned, a throat swab to diagnose strep pharyngitis may be recommended. Assessment and scoring are relatively straightforward using this scale, which has effectively reduced the number of people undergoing unnecessary testing and treatment for strep throat.</div>
<div class="s4P">Similarly, guidelines have been developed for breast cancer diagnosis with the Breast Imaging Reporting and Data System (BI-RADS), which reduces noise in the interpretations of mammograms. One study found that BI-RADS increased interrater agreement on the assessments of mammograms, demonstrating that guidelines can be effective in reducing noise in an area where variability has been significant. In pathology, there have been many successful efforts to use guidelines for the same purpose.</div>
<div class="s7D">The Depressing Case of Psychiatry</div>
<div class="s4M">In terms of noise, psychiatry is an extreme case. When diagnosing the same patient using the same diagnostic criteria, psychiatrists frequently disagree with one another. For that reason, noise <span id="page_264"></span>
reduction has been a major priority for the psychiatric community since at least the 1940s. And as we will see, despite being constantly refined, guidelines have provided only modest help in reducing noise.</div>
<div class="s4P">A 1964 study involving 91 patients and ten experienced psychiatrists found that the likelihood of an agreement between two opinions was just 57%. Another early study, involving 426 state hospital patients diagnosed independently by two psychiatrists, found agreement merely 50% of the time in their diagnosis of the kind of mental illness that was present. Yet another early study, involving 153 outpatients, found 54% agreement. In these studies, the source of the noise was not specified. Interestingly, however, some psychiatrists were found to be inclined to assign patients to specific diagnostic categories. For example, some psychiatrists were especially likely to diagnose patients with depression, and others with anxiety.</div>
<div class="s4P">As we shall soon see, levels of noise continue to be high in psychiatry. Why is this? Specialists lack a single, clear answer (which means that the explanations for noise are themselves noisy). The large set of diagnostic categories is undoubtedly one factor. But in a preliminary effort to answer that question, researchers asked one psychiatrist to interview a patient first, and then had a second psychiatrist conduct another interview after a short resting period. The two psychiatrists met afterward and, if they disagreed, discussed why they did so.</div>
<div class="s4P">One frequent reason was “inconstancy of the physician”: different schools of thought, different training, different clinical experiences, different interview styles. While a “clinician with developmental training might explain the hallucinatory experience as part of posttraumatic experience of past abuse,” a different clinician “with a biomedical orientation might explain the same hallucinations as part of a schizophrenic process.” Such differences are examples of pattern noise.</div>
<div class="s4P">Beyond physician differences, however, the main reason for noise was “inadequacy of the nomenclature.” Such observations and widespread professional dissatisfaction with psychiatric nomenclature helped motivate the 1980 revision (the third edition) of the <span class="s2WT-0">Diagnostic and Statistical Manual of Mental Disorders</span>
 (DSM-III). The manual included, for the first time, explicit and detailed <span id="page_265"></span>
criteria for diagnosing mental disorders, a first step in the direction of introducing diagnostic guidelines.</div>
<div class="s4P">DSM-III led to a dramatic increase in the research on whether diagnoses were noisy. It also proved helpful in reducing noise. But the manual was far from a complete success. Even after a significant 2000 revision of the fourth edition, DSM-IV (originally published in 1994), research showed that the level of noise remained high. On the one hand, Ahmed Aboraya and his colleagues conclude that “the use of diagnostic criteria for psychiatric disorders has been shown to increase the reliability of psychiatric diagnoses.” On the other hand, there continues to be a serious risk that “admissions of a single patient will reveal multiple diagnoses for the same patient.”</div>
<div class="s4P">Another version of the manual, DSM-5, was released in 2013. The American Psychiatric Association had hoped that DSM-5 would reduce noise because the new edition relied on more objective, clearly scaled criteria. But psychiatrists continue to show significant noise. For example, Samuel Lieblich and his colleagues find that “psychiatrists have a hard time agreeing on who does and does not have major depressive disorder.” Field trials for DSM-5 found “minimal agreement,” which “means that highly trained specialist psychiatrists under study conditions were only able to agree that a patient has depression between 4 and 15% of the time.” According to some field trials, DSM-5 actually made things worse, showing increased noise “in all major domains, with some diagnoses, such as mixed anxiety-depressive disorder… so unreliable as to appear useless in clinical practice.”</div>
<div class="s4P">The major reason for the limited success of guidelines seems to be that, in psychiatry, “the diagnostic criteria of some disorders are still vague and difficult to operationalize.” Some guidelines reduce noise by decomposing judgment into criteria on which disagreement is reduced, but to the extent that such criteria are relatively open-ended, noise remains likely. With this point in mind, prominent proposals call for more standardized diagnostic guidelines. These include (1) clarifying diagnostic criteria, moving away from vague standards; (2) producing “reference definitions” of symptoms and their level of severity, on the theory that when “clinicians agree on the presence or absence of symptoms, they are more likely to agree on the diagnosis”; and (3) using structured interviews of patients in addition to open conversation. One <span id="page_266"></span>
proposed interview guide includes twenty-four screening questions that allow for more reliable diagnosis of, for example, anxiety, depression, and eating disorders.</div>
<div class="s4P">These steps sound promising, but it is an open question to what extent they would succeed in reducing noise. In the words of one observer, “the reliance on the patient’s subjective symptoms, the clinician’s interpretation of the symptoms, and the absence of objective measure (such as a blood test) implant the seeds of diagnostic unreliability of psychiatric disorders.” In this sense, psychiatry may prove especially resistant to attempts at noise reduction.</div>
<div class="s4P">On that particular question, it is too soon to make a confident prediction. But one thing is clear. In medicine in general, guidelines have been highly successful in reducing both bias and noise. They have helped doctors, nurses, and patients and greatly improved public health in the process. The medical profession needs more of them.</div>
<div class="s84">Speaking of Guidelines in Medicine</div>
<div class="s86">
<span class="class-2">“Among doctors, the level of noise is far higher than we might have suspected. In diagnosing cancer and heart disease—even in reading X-rays—specialists sometimes disagree. That means that the treatment a patient gets might be a product of a lottery.”</span>
</div>
<div class="s88">
<span class="class-2">“Doctors like to think that they make the same decision whether it’s Monday or Friday or early in the morning or late in the afternoon. But it turns out that what doctors say and do might well depend on how tired they are.”</span>
</div>
<div class="s8A">
<span class="class-2">“Medical guidelines can make doctors less likely to blunder at a patient’s expense. Such guidelines can also help the medical profession as a whole, because they reduce variability.”</span>
</div>
</body>
</html>
