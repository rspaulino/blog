<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>part0038</title>
<link rel="stylesheet" type="text/css" href="stylesheet.css" />
</head>
<body>
<div id="page_306" class="s6B">
<a href="part0003.xhtml#page_5">CHAPTER 26</a>
</div>
<div class="s6T">
<a href="part0003.xhtml#page_5">The Costs of Noise Reduction</a>
</div>
<div class="s4M">
<span class="s2WY">W</span>
henever people are asked to eliminate noise, they might object that the necessary steps are just too expensive. In extreme circumstances, noise reduction is simply not possible. We have heard this objection in business, education, government, and elsewhere. There is a legitimate concern here, but it is easily overstated, and it is often just an excuse.</div>
<div class="s4P">To put the objection in its most appealing light, consider the case of a high school teacher who grades twenty-five essays by tenth-graders during each week of the school year. If the teacher spends no more than fifteen minutes on each essay, the grading might be noisy and therefore inaccurate and unfair. The teacher might consider a little decision hygiene, perhaps reducing the noise by asking a colleague to grade the essays as well, so that two people are reading every paper. Perhaps the teacher could accomplish the same goal by spending more time reading each essay, structuring the relatively complex process of assessment, or by reading the essays more than once and in different orders. A detailed grading guideline used as a checklist might help. Or perhaps the educator could make sure to read each essay at the same time of day, so as to reduce occasion noise.</div>
<div class="s4P">But if the teacher’s own judgments are pretty accurate and not terribly noisy, it might be sensible not to do any of these things. It might not be worth the bother. The teacher might think that using a checklist or asking a colleague to read the same papers would be a form of overkill. To know whether it is, a disciplined analysis might be necessary: how much more accuracy would the teacher gain, how important is more accuracy, and how much time and money would be required by the effort to reduce noise? We could easily imagine a <span id="page_307"></span>
limit on how much to invest in noise reduction. We could just as easily see that this limit should be different when the essays are written by ninth-graders or as senior theses, where university admission may be on the line and the stakes are higher.</div>
<div class="s4P">The basic analysis might be extended to more complex situations faced by private and public organizations of all kinds, leading them to reject some noise-reduction strategies. For some diseases, hospitals and doctors might struggle to identify simple guidelines to eliminate variability. In the case of divergent medical diagnoses, efforts to reduce noise have particular appeal; they might save lives. But the feasibility and costs of those efforts need to be taken into account. A test might eliminate noise in diagnoses, but if the test is invasive, dangerous, and costly, and if variability in diagnoses is modest and has only mild consequences, then it might not be worthwhile for all doctors to require all patients to take the test.</div>
<div class="s4P">Rarely does the evaluation of employees involve life and death. But noise can result in unfairness for employees and high costs for the firm. We have seen that efforts to reduce noise should be feasible. Are they worthwhile? Cases involving clearly mistaken evaluations might get noticed and seem embarrassing, shameful, or worse. Nonetheless, an institution might think that elaborate corrective steps are not worth the effort. Sometimes that conclusion is shortsighted, self-serving, and wrong, even catastrophically so. Some form of decision hygiene might well be worthwhile. But the belief that it is too expensive to reduce noise is not always wrong.</div>
<div class="s4P">In short, we have to compare the benefits of noise reduction with the costs. That is fair, and it is one reason noise audits are so important. In many situations, the audits reveal that noise is producing outrageous levels of unfairness, very high costs, or both. If so, the cost of noise reduction is hardly a good reason not to make the effort.</div>
<div class="s7D">Less Noise, More Mistakes?</div>
<div class="s4M">A different objection is that some noise-reduction efforts might themselves produce unacceptably high levels of error. The objection might be convincing if the instruments used to reduce noise are too <span id="page_308"></span>
blunt. In fact, some efforts at noise reduction might even increase bias. If a social media platform such as Facebook or Twitter introduced firm guidelines that call for removing all posts containing certain vulgar words, its decisions will be less noisy, but it will be taking down numerous posts that should be allowed to stay up. These false positives are a directional error—a bias.</div>
<div class="s4P">Life is full of institutional reforms that are designed to reduce the discretion of people and practices that generate noise. Many such reforms are well motivated, but some cures are worse than the disease. In <span class="s2WT-0">The Rhetoric of Reaction,</span>
 economist Albert Hirschman points to three common objections to reform efforts. First, such efforts might be perverse, in the sense that they will aggravate the very problem they are intended to solve. Second, they might be futile; they might not change things at all. Third, they put other important values in jeopardy (such as when an effort to protect labor unions and the right to unionize is said to hurt economic growth). Perversity, futility, and jeopardy might be offered as objections to noise reduction, and of the three, claims of perversity and jeopardy tend to be the most powerful. Sometimes these objections are just rhetoric—an effort to derail a reform that will actually do a great deal of good. But some noise-reduction strategies could jeopardize important values, and for others the risk of perversity might not be readily dismissed.</div>
<div class="s4P">The judges who objected to the sentencing guidelines were pointing to that risk. They were well aware of Judge Frankel’s work, and they did not deny that discretion produces noise. But they thought that reducing discretion would produce more mistakes, not fewer. Quoting Václav Havel, they insisted, “We have to abandon the arrogant belief that the world is merely a puzzle to be solved, a machine with instructions for use waiting to be discovered, a body of information to be fed into a computer in the hope that, sooner or later, it will spit out a universal solution.” One reason for rejecting the idea of universal solutions is an insistent belief that human situations are highly varied and that good judges address the variations—which might mean tolerating noise, or at least rejecting some noise-reduction strategies.</div>
<div class="s4P">In the early days of computer chess, a large airline offered a chess program for international passengers, who were invited to play against a computer. The program had several levels. At the <span id="page_309"></span>
lowest level, the program used a simple rule: place your opponent’s king in check whenever you can. The program was not noisy. It played the same way every time; it would always follow its simple rule. But the rule ensured a great deal of error. The program was terrible at chess. Even inexperienced chess players could defeat it (which was undoubtedly the point; winning air travelers are happy air travelers).</div>
<div class="s4P">Or consider the criminal sentencing policy adopted in some US states and called “three strikes and you’re out.” The idea is that if you commit three felonies, your sentence is life imprisonment—period. The policy reduces the variability that comes from random assignment of the sentencing judge. Some of its proponents were especially concerned about level noise and the possibility that some judges were too lenient with hardened criminals. Eliminating noise is the central point of the three-strikes legislation.</div>
<div class="s4P">But even if the three-strikes policy succeeds in its noise-reduction goal, we can reasonably object that the price of this success is too high. Some people who have committed three felonies should not be put away for life. Perhaps their crimes were not violent. Or their awful life circumstances might have helped lead them to crime. Maybe they show a capacity for rehabilitation. Many people think that a life sentence, inattentive to the particular circumstances, is not only too harsh but also intolerably rigid. For that reason, the price of that noise-reduction strategy is too high.</div>
<div class="s4P">Consider the case of <span class="s2WT-0">Woodson v. North Carolina,</span>
 in which the US Supreme Court held that a mandatory death sentence was unconstitutional not because it was too brutal but <span class="s2WT-0">because it was a rule.</span>
 The whole point of the mandatory death sentence was to ensure against noise—to say that under specified circumstances, murderers would have to be put to death. Invoking the need for individualized treatment, the court said that “the belief no longer prevails that every offense in a like legal category calls for an identical punishment without regard to the past life and habits of a particular offender.” According to the Supreme Court, a serious constitutional shortcoming of the mandatory death sentence is that it “treats all persons convicted of a designated offense not as uniquely individual human beings, but as members of a faceless, undifferentiated mass to be subjected to the blind infliction of the penalty of death.”</div>
<div class="s4P">The death penalty involves especially high stakes, of course, <span id="page_310"></span>
but the court’s analysis can be applied to many other situations, most of them not involving law at all. Teachers evaluating students, doctors evaluating patients, employers evaluating employees, underwriters setting insurance premiums, coaches evaluating athletes—all these people might make mistakes if they apply overly rigid, noise-reducing rules. If employers use simple rules for evaluating, promoting, or suspending employees, those rules might eliminate noise while neglecting important aspects of the employees’ performance. A noise-free scoring system that fails to take significant variables into account might be worse than reliance on (noisy) individual judgments.</div>
<div class="s4P">
<a href="part0039.xhtml">Chapter 27</a>
 considers the general idea of treating people as “uniquely individual,” rather than as “members of a faceless, undifferentiated mass.” For now, we are focusing on a more prosaic point. Some noise-reduction strategies ensure too many mistakes. They might be a lot like that foolish chess program.</div>
<div class="s4P">Still, the objection seems far more convincing than it actually is. If one noise-reduction strategy is error-prone, we should not rest content with high levels of noise. We should instead try to devise a better noise-reduction strategy—for example, aggregating judgments rather than adopting silly rules or developing wise guidelines or rules rather than foolish ones. In the interest of noise reduction, a university could say, for example, that people with the highest test scores will be admitted, and that’s it. If that rule seems too crude, the school could create a formula that takes account of test scores, grades, age, athletic achievements, family background, and more. Complex rules might be more accurate—more attuned to the full range of relevant factors. Similarly, doctors have complex rules for diagnosing some illnesses. The guidelines and rules used by professionals are not always simple or crude, and many of them help reduce noise without creating intolerably high costs (or bias). And if guidelines or rules will not work, perhaps we could introduce other forms of decision hygiene, suited to the particular situation, that will; recall aggregating judgments or using a structured process such as the mediating assessments protocol.</div>
<div class="s7D">Noiseless, Biased Algorithms</div>
<div id="page_311" class="s4M">The potentially high costs of noise reduction often come up in the context of algorithms, where there are growing objections to “algorithmic bias.” As we have seen, algorithms eliminate noise and often seem appealing for that reason. Indeed, much of this book might be taken as an argument for greater reliance on algorithms, simply because they are noiseless. But as we have also seen, noise reduction can come at an intolerable cost if greater reliance on algorithms increases discrimination on the basis of race and gender, or against members of disadvantaged groups.</div>
<div class="s4P">There are widespread fears that algorithms will in fact have that discriminatory consequence, which is undoubtedly a serious risk. In <span class="s2WT-0">Weapons of Math Destruction,</span>
 mathematician Cathy O’Neil urges that reliance on big data and decision by algorithm can embed prejudice, increase inequality, and threaten democracy itself. According to another skeptical account, “potentially biased mathematical models are remaking our lives—and neither the companies responsible for developing them nor the government is interested in addressing the problem.” According to ProPublica, an independent investigative journalism organization, COMPAS, an algorithm widely used in recidivism risk assessments, is strongly biased against members of racial minorities.</div>
<div class="s4P">No one should doubt that it is possible—even easy—to create an algorithm that is noise-free but also racist, sexist, or otherwise biased. An algorithm that explicitly uses the color of a defendant’s skin to determine whether that person should be granted bail would discriminate (and its use would be unlawful in many nations). An algorithm that takes account of whether job applicants might become pregnant would discriminate against women. In these and other cases, algorithms could eliminate unwanted variability in judgment but also embed unacceptable bias.</div>
<div class="s4P">In principle, we should be able to design an algorithm that does <span class="s2WT-0">not</span>
 take account of race or gender. Indeed, an algorithm could be designed that disregards race or gender entirely. The more challenging problem, now receiving a great deal of attention, is that an algorithm could discriminate and, in that sense, turn out to be biased, even when it does not overtly use race and gender as predictors.</div>
<div class="s4P">As we have suggested, an algorithm might be biased for two main reasons. First, by design or not, it could use predictors that are <span id="page_312"></span>
highly correlated with race or gender. For example, height and weight are correlated with gender, and the place where people grew up or where they live might well be correlated with race.</div>
<div class="s4P">Second, discrimination could also come from the source data. If an algorithm is trained on a data set that is biased, it will be biased, too. Consider “predictive policing” algorithms, which attempt to predict crime, often in order to improve the allocation of police resources. If the existing data about crime reflects the overpolicing of certain neighborhoods or the comparative overreporting of certain types of offenses, then the resulting algorithms will perpetuate or exacerbate discrimination. Whenever there is bias in the training data, it is quite possible to design, intentionally or unintentionally, an algorithm that encodes discrimination. It follows that even if an algorithm does not expressly consider race or gender, it could turn out to be as biased as human beings are. Indeed, in this regard, algorithms could be worse: since they eliminate noise, they could be more <span class="s2WT-0">reliably</span>
 biased than human judges.</div>
<div class="s4P">For many people, a key practical consideration is whether an algorithm has a disparate impact on identifiable groups. Exactly how to test for disparate impact, and how to decide what constitutes discrimination, bias, or fairness for an algorithm, are surprisingly complex topics, well beyond the scope of this book.</div>
<div class="s4P">The fact that this question can be raised at all, however, is a distinct advantage of algorithms over human judgments. For starters, we recommend careful assessment of algorithms to ensure that they do not consider inadmissible inputs and to test whether they discriminate in an objectionable way. It is much harder to subject individual human beings, whose judgments are often opaque, to the same kind of scrutiny; people sometimes discriminate unconsciously and in ways that outside observers, including the legal system, cannot easily see. So in some ways, an algorithm can be more transparent than human beings are.</div>
<div class="s4P">Undoubtedly, we need to draw attention to the costs of noiseless but biased algorithms, just as we need to consider the costs of noiseless but biased rules. The key question is whether we can design algorithms that do better than real-world human judges on a combination of criteria that matter: accuracy and noise reduction, and nondiscrimination and fairness. A great deal of evidence <span id="page_313"></span>
suggests that algorithms can outperform human beings on whatever combination of criteria we select. (Note that we said <span class="s2WT-0">can</span>
 and not <span class="s2WT-0">will.</span>
) For instance, as described in <a href="part0019.xhtml">chapter 10</a>
, an algorithm can be more accurate than human judges with respect to bail decisions while producing less racial discrimination than human beings do. Similarly, a résumé-selection algorithm can select a better <span class="s2WT-0">and more diverse</span>
 pool of talent than human résumé screeners do.</div>
<div class="s4P">These examples and many others lead to an inescapable conclusion: although a predictive algorithm in an uncertain world is unlikely to be perfect, it can be far less imperfect than noisy and often-biased human judgment. This superiority holds in terms of both validity (good algorithms almost always predict better) and discrimination (good algorithms can be less biased than human judges). If algorithms make fewer mistakes than human experts do and yet we have an intuitive preference for people, then our intuitive preferences should be carefully examined.</div>
<div class="s4P">Our broader conclusions are simple and extend well beyond the topic of algorithms. It is true that noise-reduction strategies can be costly. But much of the time their costs are merely an excuse—and not a sufficient reason to tolerate the unfairness and costs of noise. Of course, efforts to reduce noise might produce errors of their own, perhaps in the form of bias. In that case we have a serious problem, but the solution is not to abandon noise-reduction efforts; it is to come up with better ones.</div>
<div class="s84">Speaking of the Costs of Noise Reduction</div>
<div class="s86">
<span class="class-2">“If we tried to eliminate noise in education, we would have to spend a lot of money. When they grade students, teachers are noisy. We can’t have five teachers grading the same paper.”</span>
</div>
<div class="s88">
<span class="class-2">“If, instead of relying on human judgment, a social network decides that no one may use certain words, whatever the context, it will eliminate noise, but also create a lot of errors. The cure might be worse than the disease.”</span>
</div>
<div class="s88">
<span class="class-2">“True, there are rules and algorithms that are biased. But people have biases, too. What we should ask is, can we design algorithms that are both noise-free and less biased?”</span>
</div>
<div class="s8A">
<span class="class-2">“It might be costly to remove noise—but the cost is often worth incurring. Noise can be horribly unfair. And if one effort to reduce</span>
 <span id="page_314" class="class-2"></span>
<span class="class-2">noise is too crude—if we end up with guidelines or rules that are unacceptably rigid or that inadvertently produce bias—we shouldn’t just give up. We have to try again.”</span>
</div>
</body>
</html>
