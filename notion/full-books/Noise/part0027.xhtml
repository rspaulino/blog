<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>part0027</title>
<link rel="stylesheet" type="text/css" href="stylesheet.css" />
</head>
<body>
<div id="page_196" class="s6B">
<a href="part0003.xhtml#a2X4">CHAPTER 17</a>
</div>
<div class="s6T">
<a href="part0003.xhtml#a2X4">The Sources of Noise</a>
</div>
<div class="s4M">
<span class="s2WY">W</span>
e hope that by now, you agree that wherever there is judgment, there is noise. We also hope that for you, there is no longer more of it than you think. This mantra about noise motivated us when we started our project, but our thinking about the topic has evolved over the years of working on it. We now review the main lessons we have learned about the components of noise, about their respective importance in the general picture of noise, and about the place of noise in the study of judgment.</div>
<div class="s7D">The Components of Noise</div>
<div class="s4M">
<a href="part0027.xhtml#page_197">Figure 16</a>
 offers a combined graphical representation of the three equations we introduced in <a href="part0013.xhtml">chapters 5</a>
, <a href="part0014.xhtml">6</a>
, and <a href="part0026.xhtml">16</a>
. The figure illustrates three successive breakdowns of error:</div>
<div class="s5K">
<span class="class-3">• error into bias and system noise,</span>
</div>
<div class="s5N">
<span class="class-3">• system noise into level noise and pattern noise,</span>
</div>
<div class="s5W">
<span class="class-3">• pattern noise into stable pattern noise and occasion noise.</span>
</div>
<div class="s4P">You can now see how MSE breaks down into the squares of bias and of the three components of noise we have discussed.</div>
<div class="sE6">
<div class="sK">
<div class="sH-0"><img src="rsrc31U.jpg" alt="" id="page_197" class="sH-1" />
</div>
<div class="sE3">F<span class="s2WW">IGURE 16:</span>
 <span class="s2WT-0">Error, bias, and the components of noise</span>
</div>
</div>
</div>
<div class="s4P">When we began our research, we were focusing on the relative weights of bias and noise in total error. We soon concluded that noise is often a larger component of error than bias is, and certainly well worth exploring in more detail.</div>
<div class="s4P">Our early thinking on the constituents of noise was guided by the structure of complex noise audits, in which multiple people make individual judgments about multiple cases. The study of federal judges was an example, and the study of punitive damages another. Data from these studies provided solid estimates of level noise. On the other hand, because every participant judges every case but does so only once, there is no way of telling whether the residual error, which we have called pattern error, is transient or stable. In the conservative spirit of statistical analysis, the residual error is commonly labeled an error term and is treated as random. In other words, the default interpretation of pattern noise is that it consists entirely of occasion noise.</div>
<div class="s4P">This conventional interpretation of pattern noise as random error constrained our thinking for a long time. It seemed natural to <span id="page_198"></span>
focus on level noise—the consistent differences between harsh and lenient judges or between optimistic and pessimistic forecasters. We were also intrigued by evidence of the influence on judgments of the irrelevant and transient circumstances that create occasion noise.</div>
<div class="s4P">The evidence gradually led us to realize that the noisy judgments that different people make are largely determined by something that is neither a general bias of the individual nor transient and random: the persistent personal reactions of particular individuals to a multitude of features, which determine their reactions to specific cases. We eventually concluded that our default assumption about the transient nature of pattern noise should be abandoned.</div>
<div class="s4P">Though we want to be careful not to overgeneralize from what remains a limited selection of examples, the studies we have assembled, taken together, suggest that stable pattern noise is actually more significant than the other components of system noise. Because we rarely have a full picture of the components of error in the same study, it requires some triangulation to formulate this tentative conclusion. In short, here is what we know—and what we don’t.</div>
<div class="s7D">Sizing the Components</div>
<div class="s4M">First, we have several estimates of the relative weights of level noise and pattern noise. Overall, it appears that pattern noise contributes more than level noise. In the insurance company of <a href="part0009.xhtml">chapter 2</a>
, for instance, differences between underwriters in the average of the premiums they set accounted for only 20% of total system noise; the remaining 80% was pattern noise. Among the federal judges of <a href="part0014.xhtml">chapter 6</a>
, level noise (differences in average severity) represented slightly less than half of total system noise; pattern noise was the larger component. In the punitive damages experiment, the total amount of system noise varied widely depending on the scale used (punitive intent, outrage, or damages in dollars), but the share of pattern noise in that total was roughly constant: it accounted for 63%, 62%, and 61% of total system noise for the three scales used in the study. Other studies we will review in <a href="part0028.xhtml">part 5</a>
, notably on personnel decisions, are consistent with this tentative conclusion.</div>
<div id="page_199" class="s4P">The fact that in these studies level noise is generally not the larger component of system noise is already an important message, because level noise is the only form of noise that organizations can (sometimes) monitor without conducting noise audits. When cases are assigned more or less randomly to individual professionals, the differences in the average level of their decisions provide evidence of level noise. For example, studies of patent offices observed large differences in the average propensity of examiners to grant patents, with subsequent effects on the incidence of litigation about these patents. Similarly, case officers in child protection services vary in their propensity to place children in foster care, with long-term consequences for the children’s welfare. These observations are based solely on an estimation of level noise. If there is more pattern noise than level noise, then these already-shocking findings understate the magnitude of the noise problem by at least a factor of two. (There are exceptions to this tentative rule. The scandalous variability in the decisions of asylum judges is almost certainly due more to level noise than to pattern noise, which we suspect is large as well.)</div>
<div class="s4P">The next step is to analyze pattern noise by separating its two components. There are good reasons to assume that stable pattern noise, rather than occasion noise, is the dominant component. The audit of the sentences of federal judges illustrates our reasoning. Start with the extreme possibility that all pattern noise is transient. On that assumption, sentencing would be unstable and inconsistent over time, to an extent that we find implausible: we would have to expect that the average difference between judgments of <span class="s2WT-0">the same case by the same judge</span>
 on different occasions is about 2.8 years. The variability of average sentencing among judges is already shocking. The same variability in the sentences of an individual judge over occasions would be grotesque. It seems more reasonable to conclude that judges differ in their reactions to different defendants and different crimes and that these differences are highly personal but stable.</div>
<div class="s4P">To quantify more precisely how much of pattern noise is stable and how much is occasion noise, we need studies in which the same judges make two independent assessments of each case. As we have noted, obtaining two independent judgments is generally impossible in studies of judgment, because it is difficult to guarantee <span id="page_200"></span>
that the second judgment of a case is truly independent of the first. Especially when the judgment is complex, there is a high probability that the individual will recognize the problem and repeat the original judgment.</div>
<div class="s4P">A group of researchers at Princeton, led by Alexander Todorov, has designed clever experimental techniques to overcome this problem. They recruited participants from Amazon Mechanical Turk, a site where individuals provide short-term services, such as answering questionnaires, and are paid for their time. In one experiment, participants viewed pictures of faces (generated by a computer program, but perfectly indistinguishable from the faces of real people) and rated them on various attributes, such as likability and trustworthiness. The experiment was repeated, with the same faces and the same respondents, one week later.</div>
<div class="s4P">It is fair to expect less consensus in this experiment than in professional judgments such as those of sentencing judges. Everyone might agree that some people are extremely attractive and that others are extremely unattractive, but across a significant range, we expect reactions to faces to be largely idiosyncratic. Indeed, there was little agreement among observers: on the ratings of trustworthiness, for instance, differences among pictures accounted for only 18% of the variance of judgments. The remaining 82% of the variance was noise.</div>
<div class="s4P">It is also fair to expect less stability in these judgments, because the quality of judgments made by participants who are paid to answer questions online is often substantially lower than in professional settings. Nevertheless, the largest component of noise was stable pattern noise. The second largest component of noise was level noise—that is, differences among observers in their average ratings of trustworthiness. Occasion noise, though still substantial, was the smallest component.</div>
<div class="s4P">The researchers reached the same conclusions when they asked participants to make other judgments—about preferences among cars or foods, for example, or on questions that are closer to what we call professional judgments. For instance, in a replication of the study of punitive damages discussed in <a href="part0025.xhtml">chapter 15</a>
, participants rated their punitive intent in ten cases of personal injury, on two separate occasions separated by a week. Here again, stable pattern noise was the largest component. In all these studies, individuals <span id="page_201"></span>
generally did not agree with one another, but they remained quite stable in their judgments. This “consistency without consensus,” in the researchers’ words, provides clear evidence of stable pattern noise.</div>
<div class="s4P">The strongest evidence for the role of stable patterns comes from the large study of bail judges we mentioned in <a href="part0019.xhtml">chapter 10</a>
. In one part of this exceptional study, the authors created a statistical model that simulated how each judge used the available cues to decide whether to grant bail. They built custom-made models of 173 judges. Then they applied the simulated judges to make decisions about 141,833 cases, yielding 173 decisions for each case—a total of more than 24 million decisions. At our request, the authors generously carried a special analysis in which they separated the variance judgments into three components: the “true” variance of the average decisions for each of the cases, the level noise created by differences among judges in their propensity to grant bail, and the remaining pattern noise.</div>
<div class="s4P">This analysis is relevant to our argument because pattern noise, as measured in this study, is entirely stable. The random variability of occasion noise is not represented, because this is an analysis of <span class="s2WT-0">models</span>
 that predict a judge’s decision. Only the verifiably stable individual rules of prediction are included.</div>
<div class="s4P">The conclusion was unequivocal: this stable pattern noise was almost four times larger than level noise (stable pattern noise accounted for 26%, and level noise 7%, of total variance). The stable, idiosyncratic individual patterns of judgment that could be identified were much larger than the differences in across-the-board severity.</div>
<div class="s4P">All this evidence is consistent with the research on occasion noise that we reviewed in <a href="part0015.xhtml">chapter 7</a>
: while the existence of occasion noise is surprising and even disturbing, there is no indication that within-person variability is larger than between-person differences. The most important component of system noise is the one we had initially neglected: stable pattern noise, the variability among judges in their judgments of particular cases.</div>
<div class="s4P">Given the relative scarcity of relevant research, our conclusions are tentative, but they do reflect a change in how we think about noise—and about how to tackle it. In principle at least, level noise—or simple, across-the-board differences between judges<span id="page_202"></span>
—should be a relatively easy problem to measure and address. If there are abnormally “tough” graders, “cautious” child custody officers, or “risk-averse” loan officers, the organizations that employ them could aim to equalize the average level of their judgments. Universities, for instance, address this problem when they require professors to abide by a predetermined distribution of grades within each class.</div>
<div class="s4P">Unfortunately, as we now realize, focusing on level noise misses a large part of what individual differences are about. Noise is mostly a product not of level differences but of interactions: how different judges deal with particular defendants, how different teachers deal with particular students, how different social workers deal with particular families, how different leaders deal with particular visions of the future. Noise is mostly a by-product of our uniqueness, of our “judgment personality.” Reducing level noise is still a worthwhile objective, but attaining only this objective would leave most of the problem of system noise without a solution.</div>
<div class="s7D">Explaining Error</div>
<div class="s4M">We found a lot to say about noise, but the topic is almost entirely absent from public awareness and from discussions of judgment and error. Despite the evidence of its presence and the multiple mechanisms that produce it, noise is rarely mentioned as a major factor in judgment. How is this possible? Why do we never invoke noise to explain bad judgments, whereas we routinely blame biases? Why is it so unusual to give much thought to noise as a source of error, despite its ubiquity?</div>
<div class="s4P">The key to this puzzle is that although the average of errors (the bias) and the variability of errors (the noise) play equivalent roles in the error equation, we think about them in profoundly different ways. And our ordinary way of making sense of the world around us makes it all but impossible to recognize the role of noise.</div>
<div class="s4P">Earlier in this book, we noted that we easily make sense of events in hindsight, although we could not have predicted them before they happened. In the valley of the normal, events are unsurprising and easily explained.</div>
<div class="s4P">The same can be said of judgments. Like other events, <span id="page_203"></span>
judgments and decisions mostly happen in the valley of the normal; they usually do not surprise us. For one thing, judgments that produce satisfactory outcomes are normal, and seldom questioned. When the shooter who is picked for the free kick scores the goal, when the heart surgery is successful, or when a start-up prospers, we assume that the reasons the decision makers had for their choices must have been the right ones. After all, they have been proven right. Like any other unsurprising story, a success story explains itself once the outcome is known.</div>
<div class="s4P">We do, however, feel a need to explain abnormal outcomes: the bad ones and, occasionally, the surprisingly good ones—such as the shocking business gamble that pays off. Explanations that appeal to error or to special flair are far more popular than they deserve to be, because important gambles of the past easily become acts of genius or folly when their outcome is known. A well-documented psychological bias called the <span class="s2WT-0">fundamental attribution error</span>
 is a strong tendency to assign blame or credit to agents for actions and outcomes that are better explained by luck or by objective circumstances. Another bias, hindsight, distorts judgments so that outcomes that could not have been anticipated appear easily foreseeable in retrospect.</div>
<div class="s4P">Explanations for errors of judgment are not hard to come by; finding reasons for judgments is, if anything, easier than finding causes for events. We can always invoke the motives of the people making the judgments. If that is not sufficient, we can blame their incompetence. And another explanation for poor judgments has become common in recent decades: psychological bias.</div>
<div class="s4P">A substantial body of research in psychology and behavioral economics has documented a long list of psychological biases: the planning fallacy, overconfidence, loss aversion, the endowment effect, the status quo bias, excessive discounting of the future (“present bias”), and many others—including, of course, biases for or against various categories of people. Much is known about the conditions under which each of these biases is likely to influence judgments and decisions, and a fair amount is known that would allow an observer of decision making to recognize biased thinking in real time.</div>
<div class="s4P">A psychological bias is a legitimate causal explanation of a judgment error if the bias could have been predicted in advance or <span id="page_204"></span>
detected in real time. A psychological bias that is identified only after the fact can still provide a useful, if tentative, explanation if it also offers a prediction about the future. For example, the surprising rejection of a strong woman candidate for a position may suggest a more general hypothesis of gender bias that future appointments by the same committee will confirm or refute. Consider, in contrast, a causal explanation that applies only to one event: “In that case they failed, so they must have been overconfident.” The statement is completely vacuous, but it provides an illusion of understanding that can be quite satisfying. Business school professor Phil Rosenzweig has convincingly argued that empty explanations in terms of biases are common in discussions of business outcomes. Their popularity attests to the prevalent need for causal stories that make sense of experience.</div>
<div class="s7D">Noise Is Statistical</div>
<div class="s4M">As we noted in <a href="part0021.xhtml">chapter 12</a>
, our normal way of thinking is causal. We naturally attend to the particular, following and creating causally coherent stories about individual cases, in which failures are often attributed to errors, and errors to biases. The ease with which bad judgments can be explained leaves no space for noise in our accounts of errors.</div>
<div class="s4P">The invisibility of noise is a direct consequence of causal thinking. Noise is inherently statistical: it becomes visible only when we think statistically about an ensemble of similar judgments. Indeed, it then becomes hard to miss: it is the variability in the backward-looking statistics about sentencing decisions and underwriting premiums. It is the range of possibilities when you and others consider how to predict a future outcome. It is the scatter of the hits on the target. Causally, noise is nowhere; statistically, it is everywhere.</div>
<div class="s4P">Unfortunately, taking the statistical view is not easy. We effortlessly invoke causes for the events we observe, but thinking statistically about them must be learned and remains effortful. Causes are natural; statistics are difficult.</div>
<div class="s4P">The result is a marked imbalance in how we view bias and noise as sources of error. If you have been exposed to any <span id="page_205"></span>
introductory psychology, you probably remember the illustrations in which a salient and richly detailed figure stands out from an indistinct background. Our attention is firmly fixed on the figure even when it is small against the background. The figure/ground demonstrations are an apt metaphor for our intuitions about bias and noise: bias is a compelling figure, while noise is the background to which we pay no attention. That is how we remain largely unaware of a large flaw in our judgment.</div>
<div class="s84">Speaking of the Sources of Noise</div>
<div class="s86">
<span class="class-2">“We easily see differences in the average level of judgments, but how large is the pattern noise we do not see?”</span>
</div>
<div class="s88">
<span class="class-2">“You say this judgment was caused by biases, but would you say the same thing if the outcome had been different? And can you tell if there was noise?”</span>
</div>
<div class="s8A">
<span class="class-2">“We are rightly focused on reducing biases. Let’s also worry about reducing noise.”</span>
</div>
</body>
</html>
